{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "## From the end of EDA:\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "So the moral of the story currently is that we have at the minimum a couple of heuristics for choosing players:\n",
    "\n",
    "- Choose value players, ie players with moderate price tags but good matchups\n",
    "- Choose players based on Def they play\n",
    "- Avoid expensive players, since statistically they are unable to produce high scores consistently.\n",
    "\n",
    "With these guidelines, week 1 will be a total gamble, since we won't have any real data besides salaries. Week 2 will be the first time we can use any defensive data to help with our decision making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal for this notebook:\n",
    "\n",
    "Based on the conclusions from the EDA, we want to see if we can find a model that confirms these ideas across seasons, and also has a high enough (cross-validated) accuracy to warrant trying to use this with real money."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "Sci-kit Learn says, according to https://scikit-learn.org/stable/tutorial/machine_learning_map/, that the model to use should be either Lasso or Elastic net, but we are going to try many different models to see what produces the best result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic\n",
    "\n",
    "The idea behind this notebook is that player performances follow a predictable pattern, and therefore output should be directly predictable. The benefit of this would be to predict high performance players across each position and draft high scoring lineups. \n",
    "\n",
    "Obviously we want to get as many high performers as possible, but getting 100% accuracy on that seems implausible. \n",
    "\n",
    "That being said, if we can come up with a model that correctly guesses players scoring more than 15 points over 50% of the time, that'd be an impressive edge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None # to remove some false positive warnings\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, ElasticNetCV, RidgeCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weekly_data(week, year):\n",
    "    file_path = f\"./csv's/{year}/year-{year}-week-{week}-DK-player_data.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "def get_ytd_season_data(year, current_week):\n",
    "    df = get_weekly_data(1,year)\n",
    "    for week in range(2,current_week+1):\n",
    "        try:\n",
    "            df = df.append(get_weekly_data(week, year), ignore_index=True)\n",
    "        except:\n",
    "            print(\"No data for week: \"+str(week))\n",
    "    df = df.drop(['Unnamed: 0', 'Year'], axis=1)\n",
    "    return df\n",
    "\n",
    "def get_season_data(year, drop_year=True):\n",
    "    df = get_weekly_data(1,year)\n",
    "    for week in range(2,17):\n",
    "        try:\n",
    "            df = df.append(get_weekly_data(week, year), ignore_index=True)\n",
    "        except:\n",
    "            print(\"No data for week: \"+str(week))\n",
    "    if drop_year:\n",
    "        df = df.drop(['Unnamed: 0', 'Year'], axis=1)\n",
    "    else:\n",
    "        df = df.drop(['Unnamed: 0'], axis=1)\n",
    "    return df\n",
    "\n",
    "def get_all_seasons(drop_year=False):\n",
    "    df = get_season_data(2014, drop_year)\n",
    "    for year in range(2015,datetime.today().year+1):\n",
    "        try:\n",
    "            df = df.append(get_season_data(year, drop_year), ignore_index=True)\n",
    "        except:\n",
    "            print(\"No data for year: \"+str(year))\n",
    "    return df\n",
    "\n",
    "def scale_features(sc, X_train, X_test):\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "def handle_nulls(df):\n",
    "    # players that have nulls for any of the columns are \n",
    "    # extremely likely to be under performing or going into a bye.\n",
    "    # the one caveat is that some are possibly coming off a bye.\n",
    "    # to handle this later, probably will drop them, save those\n",
    "    # as a variable, and then re-merge after getting rid of the other\n",
    "    # null values.\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "def train_test_split_dicts(x_dict, y_dict, idx):\n",
    "    X = x_dict[idx]\n",
    "    y = y_dict[idx+1]\n",
    "    X = X.iloc[:,:-1]\n",
    "    # create a df with consecutive weeks' stats on the same row\n",
    "    combined = pd.merge(X, y, how=\"right\", on=[\"Name\"])\n",
    "    # eliminate players going into a bye (also removes players coming off a bye)\n",
    "    combined = handle_nulls(combined)\n",
    "    x_filt = combined['Week_x']==idx\n",
    "    y_filt = combined['Week_y']==idx+1, ['scoring_potential']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(combined.loc[x_filt],\n",
    "                                                        combined.loc[y_filt], \n",
    "                                                        test_size=0.3,\n",
    "                                                        random_state=0)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def eval_model(df):\n",
    "    df['score_ratio'] = round(df['actual_points'] / df['pred'],4)\n",
    "    return df\n",
    "\n",
    "def remove_outliers_btwn_ij(df, i=-1, j=5):\n",
    "    \n",
    "    s = df.loc[(df.score_ratio > i) & (df.score_ratio < j)]\n",
    "    return s, i, j\n",
    "\n",
    "def summarize_df(df, o_u_thresh=15):\n",
    "    df = eval_model(df)\n",
    "    print(f\"Total entries analyzed: {len(df)}\")\n",
    "    s, i, j = remove_outliers_btwn_ij(df)\n",
    "    print(f\"Total entries after outliers removed: {len(s)}. Left boundary: {i}x Right Boundary: {j}x\")\n",
    "    correct_preds_over_thresh = s[(s.pred >= o_u_thresh)&(s.actual_points>=o_u_thresh)]\n",
    "    correct_preds_under_thresh = s[(s.pred <= o_u_thresh)&(s.actual_points<=o_u_thresh)]\n",
    "    incorrect_preds_under_thresh = s[(s.pred <= o_u_thresh)&(s.actual_points>=o_u_thresh)]\n",
    "    incorrect_preds_over_thresh = s[(s.pred >= o_u_thresh)&(s.actual_points<=o_u_thresh)]\n",
    "    print(f\"Correct predictions of over {o_u_thresh} pts: {len(correct_preds_over_thresh)}. Percent: {round(len(correct_preds_over_thresh)/len(s)*100,2)}\") # True Positive\n",
    "    print(f\"Correct predictions of under {o_u_thresh} pts: {len(correct_preds_under_thresh)}. Percent: {round(len(correct_preds_under_thresh)/len(s)*100,2)}\") # True Negative\n",
    "    print(f\"Incorrect predictions of over {o_u_thresh} pts: {len(incorrect_preds_over_thresh)}. Percent: {round(len(incorrect_preds_over_thresh)/len(s)*100,2)}\") # False Positive\n",
    "    print(f\"Incorrect predictions of under {o_u_thresh} pts: {len(incorrect_preds_under_thresh)}. Percent: {round(len(incorrect_preds_under_thresh)/len(s)*100,2)}\") # False Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "season = 2020\n",
    "week = 6\n",
    "next_week = week + 1\n",
    "dataset = get_season_data(season)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>Name</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Team</th>\n",
       "      <th>h/a</th>\n",
       "      <th>Oppt</th>\n",
       "      <th>DK points</th>\n",
       "      <th>DK salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Wilson, Russell</td>\n",
       "      <td>QB</td>\n",
       "      <td>sea</td>\n",
       "      <td>a</td>\n",
       "      <td>atl</td>\n",
       "      <td>34.78</td>\n",
       "      <td>7000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Rodgers, Aaron</td>\n",
       "      <td>QB</td>\n",
       "      <td>gnb</td>\n",
       "      <td>a</td>\n",
       "      <td>min</td>\n",
       "      <td>33.76</td>\n",
       "      <td>6300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Josh</td>\n",
       "      <td>QB</td>\n",
       "      <td>buf</td>\n",
       "      <td>h</td>\n",
       "      <td>nyj</td>\n",
       "      <td>33.18</td>\n",
       "      <td>6500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Ryan, Matt</td>\n",
       "      <td>QB</td>\n",
       "      <td>atl</td>\n",
       "      <td>h</td>\n",
       "      <td>sea</td>\n",
       "      <td>27.90</td>\n",
       "      <td>6700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Jackson, Lamar</td>\n",
       "      <td>QB</td>\n",
       "      <td>bal</td>\n",
       "      <td>h</td>\n",
       "      <td>cle</td>\n",
       "      <td>27.50</td>\n",
       "      <td>8100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6548</th>\n",
       "      <td>16</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>Def</td>\n",
       "      <td>ind</td>\n",
       "      <td>a</td>\n",
       "      <td>pit</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6549</th>\n",
       "      <td>16</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>Def</td>\n",
       "      <td>jac</td>\n",
       "      <td>h</td>\n",
       "      <td>chi</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6550</th>\n",
       "      <td>16</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Def</td>\n",
       "      <td>ten</td>\n",
       "      <td>a</td>\n",
       "      <td>gnb</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6551</th>\n",
       "      <td>16</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Def</td>\n",
       "      <td>hou</td>\n",
       "      <td>h</td>\n",
       "      <td>cin</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>2800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6552</th>\n",
       "      <td>16</td>\n",
       "      <td>New England</td>\n",
       "      <td>Def</td>\n",
       "      <td>nwe</td>\n",
       "      <td>h</td>\n",
       "      <td>buf</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>2900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6552 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Week             Name  Pos Team h/a Oppt  DK points  DK salary\n",
       "0        1  Wilson, Russell   QB  sea   a  atl      34.78     7000.0\n",
       "1        1   Rodgers, Aaron   QB  gnb   a  min      33.76     6300.0\n",
       "2        1      Allen, Josh   QB  buf   h  nyj      33.18     6500.0\n",
       "3        1       Ryan, Matt   QB  atl   h  sea      27.90     6700.0\n",
       "4        1   Jackson, Lamar   QB  bal   h  cle      27.50     8100.0\n",
       "...    ...              ...  ...  ...  ..  ...        ...        ...\n",
       "6548    16     Indianapolis  Def  ind   a  pit       0.00     3200.0\n",
       "6549    16     Jacksonville  Def  jac   h  chi      -1.00     2200.0\n",
       "6550    16        Tennessee  Def  ten   a  gnb      -1.00     2600.0\n",
       "6551    16          Houston  Def  hou   h  cin      -4.00     2800.0\n",
       "6552    16      New England  Def  nwe   h  buf      -4.00     2900.0\n",
       "\n",
       "[6552 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = handle_nulls(dataset)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>Name</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Team</th>\n",
       "      <th>h/a</th>\n",
       "      <th>Oppt</th>\n",
       "      <th>DK points</th>\n",
       "      <th>DK salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>1</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>Def</td>\n",
       "      <td>nor</td>\n",
       "      <td>h</td>\n",
       "      <td>tam</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Def</td>\n",
       "      <td>was</td>\n",
       "      <td>h</td>\n",
       "      <td>phi</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1</td>\n",
       "      <td>Baltimore</td>\n",
       "      <td>Def</td>\n",
       "      <td>bal</td>\n",
       "      <td>h</td>\n",
       "      <td>cle</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1</td>\n",
       "      <td>New England</td>\n",
       "      <td>Def</td>\n",
       "      <td>nwe</td>\n",
       "      <td>h</td>\n",
       "      <td>mia</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>LA Chargers</td>\n",
       "      <td>Def</td>\n",
       "      <td>lac</td>\n",
       "      <td>a</td>\n",
       "      <td>cin</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6548</th>\n",
       "      <td>16</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>Def</td>\n",
       "      <td>ind</td>\n",
       "      <td>a</td>\n",
       "      <td>pit</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6549</th>\n",
       "      <td>16</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>Def</td>\n",
       "      <td>jac</td>\n",
       "      <td>h</td>\n",
       "      <td>chi</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6550</th>\n",
       "      <td>16</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Def</td>\n",
       "      <td>ten</td>\n",
       "      <td>a</td>\n",
       "      <td>gnb</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6551</th>\n",
       "      <td>16</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Def</td>\n",
       "      <td>hou</td>\n",
       "      <td>h</td>\n",
       "      <td>cin</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6552</th>\n",
       "      <td>16</td>\n",
       "      <td>New England</td>\n",
       "      <td>Def</td>\n",
       "      <td>nwe</td>\n",
       "      <td>h</td>\n",
       "      <td>buf</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Week          Name  Pos Team h/a Oppt  DK points  DK salary\n",
       "410      1   New Orleans  Def  nor   h  tam       17.0     2400.0\n",
       "411      1    Washington  Def  was   h  phi       15.0     2000.0\n",
       "412      1     Baltimore  Def  bal   h  cle       15.0     3100.0\n",
       "413      1   New England  Def  nwe   h  mia       11.0     3200.0\n",
       "414      1   LA Chargers  Def  lac   a  cin       11.0     2800.0\n",
       "...    ...           ...  ...  ...  ..  ...        ...        ...\n",
       "6548    16  Indianapolis  Def  ind   a  pit        0.0     3200.0\n",
       "6549    16  Jacksonville  Def  jac   h  chi       -1.0     2200.0\n",
       "6550    16     Tennessee  Def  ten   a  gnb       -1.0     2600.0\n",
       "6551    16       Houston  Def  hou   h  cin       -4.0     2800.0\n",
       "6552    16   New England  Def  nwe   h  buf       -4.0     2900.0\n",
       "\n",
       "[480 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_df = df.loc[df.Pos == 'Def']\n",
    "def_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>Name</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Team</th>\n",
       "      <th>h/a</th>\n",
       "      <th>Oppt</th>\n",
       "      <th>DK points</th>\n",
       "      <th>DK salary</th>\n",
       "      <th>fantasy_points_allowed_lw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>1</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>Def</td>\n",
       "      <td>nor</td>\n",
       "      <td>h</td>\n",
       "      <td>tam</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Def</td>\n",
       "      <td>was</td>\n",
       "      <td>h</td>\n",
       "      <td>phi</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>1</td>\n",
       "      <td>Baltimore</td>\n",
       "      <td>Def</td>\n",
       "      <td>bal</td>\n",
       "      <td>h</td>\n",
       "      <td>cle</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1</td>\n",
       "      <td>New England</td>\n",
       "      <td>Def</td>\n",
       "      <td>nwe</td>\n",
       "      <td>h</td>\n",
       "      <td>mia</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>LA Chargers</td>\n",
       "      <td>Def</td>\n",
       "      <td>lac</td>\n",
       "      <td>a</td>\n",
       "      <td>cin</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6548</th>\n",
       "      <td>16</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>Def</td>\n",
       "      <td>ind</td>\n",
       "      <td>a</td>\n",
       "      <td>pit</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>118.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6549</th>\n",
       "      <td>16</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>Def</td>\n",
       "      <td>jac</td>\n",
       "      <td>h</td>\n",
       "      <td>chi</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>120.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6550</th>\n",
       "      <td>16</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Def</td>\n",
       "      <td>ten</td>\n",
       "      <td>a</td>\n",
       "      <td>gnb</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>102.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6551</th>\n",
       "      <td>16</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Def</td>\n",
       "      <td>hou</td>\n",
       "      <td>h</td>\n",
       "      <td>cin</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>102.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6552</th>\n",
       "      <td>16</td>\n",
       "      <td>New England</td>\n",
       "      <td>Def</td>\n",
       "      <td>nwe</td>\n",
       "      <td>h</td>\n",
       "      <td>buf</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>98.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Week          Name  Pos Team h/a Oppt  DK points  DK salary  \\\n",
       "410      1   New Orleans  Def  nor   h  tam       17.0     2400.0   \n",
       "411      1    Washington  Def  was   h  phi       15.0     2000.0   \n",
       "412      1     Baltimore  Def  bal   h  cle       15.0     3100.0   \n",
       "413      1   New England  Def  nwe   h  mia       11.0     3200.0   \n",
       "414      1   LA Chargers  Def  lac   a  cin       11.0     2800.0   \n",
       "...    ...           ...  ...  ...  ..  ...        ...        ...   \n",
       "6548    16  Indianapolis  Def  ind   a  pit        0.0     3200.0   \n",
       "6549    16  Jacksonville  Def  jac   h  chi       -1.0     2200.0   \n",
       "6550    16     Tennessee  Def  ten   a  gnb       -1.0     2600.0   \n",
       "6551    16       Houston  Def  hou   h  cin       -4.0     2800.0   \n",
       "6552    16   New England  Def  nwe   h  buf       -4.0     2900.0   \n",
       "\n",
       "      fantasy_points_allowed_lw  \n",
       "410                        0.00  \n",
       "411                        0.00  \n",
       "412                        0.00  \n",
       "413                        0.00  \n",
       "414                        0.00  \n",
       "...                         ...  \n",
       "6548                     118.52  \n",
       "6549                     120.90  \n",
       "6550                     102.98  \n",
       "6551                     102.62  \n",
       "6552                      98.30  \n",
       "\n",
       "[480 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_df['fantasy_points_allowed_lw'] = 0\n",
    "df['Oppt_pts_allowed_lw'] = 0\n",
    "def_teams = [x for x in def_df['Team'].unique()]\n",
    "\n",
    "for week in range(1,17):\n",
    "    for team in def_teams:\n",
    "        try:\n",
    "            offense_df1 = df.loc[(df['Oppt']==team)&(df['Week']==week)]\n",
    "            offense_df2 = df.loc[(df['Oppt']==team)&(df['Week']==week+1)]\n",
    "            sum_ = offense_df1['DK points'].sum()\n",
    "            def_df.loc[(df['Team']==team)&(df['Week']==week+1), 'fantasy_points_allowed_lw'] = sum_\n",
    "            df.loc[(df['Oppt']==team)&(df['Week']==week+1), 'Oppt_pts_allowed_lw'] = sum_\n",
    "        except:\n",
    "            print('couldnt append data')\n",
    "            pass\n",
    "\n",
    "def_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.Week != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(labels='DK points', axis=1)\n",
    "y = df['DK points']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>Name</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Team</th>\n",
       "      <th>h/a</th>\n",
       "      <th>Oppt</th>\n",
       "      <th>DK salary</th>\n",
       "      <th>Oppt_pts_allowed_lw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>2</td>\n",
       "      <td>Prescott, Dak</td>\n",
       "      <td>QB</td>\n",
       "      <td>dal</td>\n",
       "      <td>h</td>\n",
       "      <td>atl</td>\n",
       "      <td>6800.0</td>\n",
       "      <td>139.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>2</td>\n",
       "      <td>Newton, Cam</td>\n",
       "      <td>QB</td>\n",
       "      <td>nwe</td>\n",
       "      <td>a</td>\n",
       "      <td>sea</td>\n",
       "      <td>6400.0</td>\n",
       "      <td>143.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>2</td>\n",
       "      <td>Allen, Josh</td>\n",
       "      <td>QB</td>\n",
       "      <td>buf</td>\n",
       "      <td>a</td>\n",
       "      <td>mia</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>89.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>2</td>\n",
       "      <td>Wilson, Russell</td>\n",
       "      <td>QB</td>\n",
       "      <td>sea</td>\n",
       "      <td>h</td>\n",
       "      <td>nwe</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>61.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>2</td>\n",
       "      <td>Murray, Kyler</td>\n",
       "      <td>QB</td>\n",
       "      <td>ari</td>\n",
       "      <td>h</td>\n",
       "      <td>was</td>\n",
       "      <td>6100.0</td>\n",
       "      <td>90.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6548</th>\n",
       "      <td>16</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>Def</td>\n",
       "      <td>ind</td>\n",
       "      <td>a</td>\n",
       "      <td>pit</td>\n",
       "      <td>3200.0</td>\n",
       "      <td>64.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6549</th>\n",
       "      <td>16</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>Def</td>\n",
       "      <td>jac</td>\n",
       "      <td>h</td>\n",
       "      <td>chi</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>110.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6550</th>\n",
       "      <td>16</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Def</td>\n",
       "      <td>ten</td>\n",
       "      <td>a</td>\n",
       "      <td>gnb</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>81.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6551</th>\n",
       "      <td>16</td>\n",
       "      <td>Houston</td>\n",
       "      <td>Def</td>\n",
       "      <td>hou</td>\n",
       "      <td>h</td>\n",
       "      <td>cin</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>67.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6552</th>\n",
       "      <td>16</td>\n",
       "      <td>New England</td>\n",
       "      <td>Def</td>\n",
       "      <td>nwe</td>\n",
       "      <td>h</td>\n",
       "      <td>buf</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>72.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6110 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Week             Name  Pos Team h/a Oppt  DK salary  Oppt_pts_allowed_lw\n",
       "442      2    Prescott, Dak   QB  dal   h  atl     6800.0               139.48\n",
       "443      2      Newton, Cam   QB  nwe   a  sea     6400.0               143.00\n",
       "444      2      Allen, Josh   QB  buf   a  mia     6700.0                89.70\n",
       "445      2  Wilson, Russell   QB  sea   h  nwe     6500.0                61.14\n",
       "446      2    Murray, Kyler   QB  ari   h  was     6100.0                90.50\n",
       "...    ...              ...  ...  ...  ..  ...        ...                  ...\n",
       "6548    16     Indianapolis  Def  ind   a  pit     3200.0                64.66\n",
       "6549    16     Jacksonville  Def  jac   h  chi     2200.0               110.74\n",
       "6550    16        Tennessee  Def  ten   a  gnb     2600.0                81.62\n",
       "6551    16          Houston  Def  hou   h  cin     2800.0                67.40\n",
       "6552    16      New England  Def  nwe   h  buf     2900.0                72.48\n",
       "\n",
       "[6110 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442     43.80\n",
       "443     38.58\n",
       "444     37.48\n",
       "445     34.42\n",
       "446     33.14\n",
       "        ...  \n",
       "6548     0.00\n",
       "6549    -1.00\n",
       "6550    -1.00\n",
       "6551    -4.00\n",
       "6552    -4.00\n",
       "Name: DK points, Length: 6110, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode data - label encoding, because one hot encoding was \n",
    "# creating huge amounts of unbalanced data\n",
    "# borrowed from https://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn\n",
    "# d = defaultdict(LabelEncoder)\n",
    "# X_le = X.apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Week  DK salary  Oppt_pts_allowed_lw  Name_Abdullah, Ameer  \\\n",
      "442      2     6800.0               139.48                     0   \n",
      "443      2     6400.0               143.00                     0   \n",
      "444      2     6700.0                89.70                     0   \n",
      "445      2     6500.0                61.14                     0   \n",
      "446      2     6100.0                90.50                     0   \n",
      "...    ...        ...                  ...                   ...   \n",
      "6548    16     3200.0                64.66                     0   \n",
      "6549    16     2200.0               110.74                     0   \n",
      "6550    16     2600.0                81.62                     0   \n",
      "6551    16     2800.0                67.40                     0   \n",
      "6552    16     2900.0                72.48                     0   \n",
      "\n",
      "      Name_Adams, Davante  Name_Adams, Josh  Name_Agholor, Nelson  \\\n",
      "442                     0                 0                     0   \n",
      "443                     0                 0                     0   \n",
      "444                     0                 0                     0   \n",
      "445                     0                 0                     0   \n",
      "446                     0                 0                     0   \n",
      "...                   ...               ...                   ...   \n",
      "6548                    0                 0                     0   \n",
      "6549                    0                 0                     0   \n",
      "6550                    0                 0                     0   \n",
      "6551                    0                 0                     0   \n",
      "6552                    0                 0                     0   \n",
      "\n",
      "      Name_Agnew, Jamal  Name_Ahmed, Salvon  Name_Aiyuk, Brandon  ...  \\\n",
      "442                   0                   0                    0  ...   \n",
      "443                   0                   0                    0  ...   \n",
      "444                   0                   0                    0  ...   \n",
      "445                   0                   0                    0  ...   \n",
      "446                   0                   0                    0  ...   \n",
      "...                 ...                 ...                  ...  ...   \n",
      "6548                  0                   0                    0  ...   \n",
      "6549                  0                   0                    0  ...   \n",
      "6550                  0                   0                    0  ...   \n",
      "6551                  0                   0                    0  ...   \n",
      "6552                  0                   0                    0  ...   \n",
      "\n",
      "      Oppt_nwe  Oppt_nyg  Oppt_nyj  Oppt_phi  Oppt_pit  Oppt_sea  Oppt_sfo  \\\n",
      "442          0         0         0         0         0         0         0   \n",
      "443          0         0         0         0         0         1         0   \n",
      "444          0         0         0         0         0         0         0   \n",
      "445          1         0         0         0         0         0         0   \n",
      "446          0         0         0         0         0         0         0   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "6548         0         0         0         0         1         0         0   \n",
      "6549         0         0         0         0         0         0         0   \n",
      "6550         0         0         0         0         0         0         0   \n",
      "6551         0         0         0         0         0         0         0   \n",
      "6552         0         0         0         0         0         0         0   \n",
      "\n",
      "      Oppt_tam  Oppt_ten  Oppt_was  \n",
      "442          0         0         0  \n",
      "443          0         0         0  \n",
      "444          0         0         0  \n",
      "445          0         0         0  \n",
      "446          0         0         1  \n",
      "...        ...       ...       ...  \n",
      "6548         0         0         0  \n",
      "6549         0         0         0  \n",
      "6550         0         0         0  \n",
      "6551         0         0         0  \n",
      "6552         0         0         0  \n",
      "\n",
      "[6110 rows x 705 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled Data\n",
    "sc = StandardScaler()\n",
    "scaled_X_train, scaled_X_test = scale_features(sc, X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_use = 'scaled'\n",
    "# data_to_use = 'un-scaled' # comment out this line for using scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_to_use == 'scaled':\n",
    "    X_train = scaled_X_train\n",
    "    X_test = scaled_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Boost Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19.08,  7.72,  3.58, ...,  1.62, 17.41,  6.01])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in range(0, len(y_pred)):\n",
    "    y_pred[x] = float(round(y_pred[x],2))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.88048518,  2.79764506, -1.09840776, ..., -0.18096625,\n",
       "        -0.17731676, -0.17975696],\n",
       "       [-1.59698235,  0.1546044 ,  0.63083919, ..., -0.18096625,\n",
       "        -0.17731676, -0.17975696],\n",
       "       [-0.92130939, -0.31978751,  0.72640284, ..., -0.18096625,\n",
       "        -0.17731676, -0.17975696],\n",
       "       ...,\n",
       "       [ 0.88048518, -1.06526052, -1.06257139, ..., -0.18096625,\n",
       "        -0.17731676, -0.17975696],\n",
       "       [-1.37175803,  1.91663151,  0.51422879, ..., -0.18096625,\n",
       "        -0.17731676,  5.56306682],\n",
       "       [-1.37175803,  0.56122604,  1.48579254, ..., -0.18096625,\n",
       "        -0.17731676, -0.17975696]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = X_test.copy()\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-0528eda4b77f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# https://stackoverflow.com/questions/22548731/how-to-reverse-sklearn-onehotencoder-transform-to-recover-original-data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mone_hot_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdf_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'player_name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mone_hot_columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdf_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pred'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "# how to decode one hot columns: \n",
    "# https://stackoverflow.com/questions/49372640/python-pandas-how-to-reverse-one-hot-encoding-back-to-categorical\n",
    "# https://stackoverflow.com/questions/22548731/how-to-reverse-sklearn-onehotencoder-transform-to-recover-original-data\n",
    "\n",
    "one_hot_columns = (df_results.iloc[:, 2:] == 1).idxmax(1)\n",
    "df_results['player_name'] = one_hot_columns\n",
    "df_results['pred'] = y_pred\n",
    "df_results['actual_points'] = y_test\n",
    "df_results['player_name'] = df_results['player_name'].str.replace(\"Name_\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", 10)\n",
    "# df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_cols = ['Week', 'DK salary', 'player_name', 'pred', 'actual_points']\n",
    "df_results_linear = df_results[subset_cols]\n",
    "df_results_linear = df_results_linear.sort_values(by='Week')\n",
    "df_results_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg = LassoCV()\n",
    "lasso_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = lasso_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0, len(y_pred2)):\n",
    "    y_pred2[x] = float(round(y_pred2[x],2))\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['pred'] = y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_cols = ['Week', 'DK salary', 'player_name', 'pred', 'actual_points']\n",
    "df_results_lasso = df_results[subset_cols]\n",
    "df_results_lasso = df_results_lasso.sort_values(by='Week')\n",
    "df_results_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_net_reg = ElasticNetCV()\n",
    "elastic_net_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = elastic_net_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0, len(y_pred3)):\n",
    "    y_pred3[x] = float(round(y_pred3[x],2))\n",
    "y_pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['pred'] = y_pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_cols = ['Week', 'DK salary', 'player_name', 'pred', 'actual_points']\n",
    "df_results_elastic = df_results[subset_cols]\n",
    "df_results_elastic = df_results_elastic.sort_values(by='Week')\n",
    "df_results_elastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg = RidgeCV()\n",
    "ridge_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4 = ridge_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0, len(y_pred4)):\n",
    "    y_pred4[x] = float(round(y_pred4[x],2))\n",
    "y_pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['pred'] = y_pred4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_cols = ['Week', 'DK salary', 'player_name', 'pred', 'actual_points']\n",
    "df_results_ridge = df_results[subset_cols]\n",
    "df_results_ridge = df_results_ridge.sort_values(by='Week')\n",
    "df_results_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_reg = DecisionTreeRegressor()\n",
    "decision_tree_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred5 = decision_tree_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0, len(y_pred5)):\n",
    "    y_pred5[x] = float(round(y_pred5[x],2))\n",
    "y_pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['pred'] = y_pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_cols = ['Week', 'DK salary', 'player_name', 'pred', 'actual_points']\n",
    "df_results_dt = df_results[subset_cols]\n",
    "df_results_dt = df_results_dt.sort_values(by='Week')\n",
    "df_results_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_reg = RandomForestRegressor()\n",
    "random_forest_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred6 = random_forest_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0, len(y_pred6)):\n",
    "    y_pred6[x] = float(round(y_pred6[x],2))\n",
    "y_pred6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['pred'] = y_pred6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_cols = ['Week', 'DK salary', 'player_name', 'pred', 'actual_points']\n",
    "df_results_rf = df_results[subset_cols]\n",
    "df_results_rf = df_results_rf.sort_values(by='Week')\n",
    "df_results_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boost Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost_reg = AdaBoostRegressor()\n",
    "ada_boost_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred7 = ada_boost_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0, len(y_pred7)):\n",
    "    y_pred7[x] = float(round(y_pred7[x],2))\n",
    "y_pred7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['pred'] = y_pred7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_cols = ['Week', 'DK salary', 'player_name', 'pred', 'actual_points']\n",
    "df_results_ada = df_results[subset_cols]\n",
    "df_results_ada = df_results_ada.sort_values(by='Week')\n",
    "df_results_ada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boost_reg = GradientBoostingRegressor()\n",
    "gradient_boost_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred8 = gradient_boost_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0, len(y_pred8)):\n",
    "    y_pred8[x] = float(round(y_pred8[x],2))\n",
    "y_pred8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['pred'] = y_pred8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_cols = ['Week', 'DK salary', 'player_name', 'pred', 'actual_points']\n",
    "df_results_grad = df_results[subset_cols]\n",
    "df_results_grad = df_results_grad.sort_values(by='Week')\n",
    "df_results_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = XGBRegressor()\n",
    "xgb_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred9 = xgb_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0, len(y_pred9)):\n",
    "    y_pred9[x] = float(round(y_pred9[x],2))\n",
    "y_pred9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['pred'] = y_pred9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_cols = ['Week', 'DK salary', 'player_name', 'pred', 'actual_points']\n",
    "df_results_xgb = df_results[subset_cols]\n",
    "df_results_xgb = df_results_xgb.sort_values(by='Week')\n",
    "df_results_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_df(df_results_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_df(df_results_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_df(df_results_elastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_df(df_results_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summarize_df(df_results_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_df(df_results_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_df(df_results_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_df(df_results_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_df(df_results_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter with lasso / elastic and then run ada boost as predictor\n",
    "y_pred_filt = lasso_reg.predict(X_test)\n",
    "y_pred_filt = elastic_net_reg.predict(X_test) # just comment this line out to try lasso (in my testing, results don't change)\n",
    "new_df_results = X_test.copy()\n",
    "new_df_results['pred'] = y_pred_filt\n",
    "new_df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = new_df_results[new_df_results['pred']>15]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.drop(labels=['pred'], axis=1)\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = ada_boost_reg.predict(df_filtered)\n",
    "final_df_results = df_filtered.copy()\n",
    "final_df_results['pred'] = y_pred_final\n",
    "final_df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_columns = (final_df_results.iloc[:, 2:] == 1).idxmax(1)\n",
    "final_df_results['player_name'] = one_hot_columns\n",
    "subset_cols = ['Week', 'DK salary', 'player_name', 'pred']\n",
    "final_df_results = final_df_results[subset_cols]\n",
    "final_df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_results['player_name'] = final_df_results['player_name'].str.replace(\"Name_\", \"\")\n",
    "final_df_results['actual_points'] = 0\n",
    "final_df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_arr = [num for num in final_df_results['Week']]\n",
    "player_arr = [name for name in final_df_results['player_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(final_df_results)):\n",
    "    num = df_results.loc[(df_results['Week']==week_arr[i])&(df_results['player_name']==player_arr[i]), 'actual_points']\n",
    "    final_df_results.loc[(final_df_results['Week']==week_arr[i])&(final_df_results['player_name']==player_arr[i]), 'actual_points'] = num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_df(final_df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = cross_val_score(estimator = elastic_net_reg, X = X_train, y = y_train, cv = 10)\n",
    "print(f\"Accuracy: {accuracies.mean()*100}%\")\n",
    "print(f\"Standard Deviation: {accuracies.std()*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = cross_val_score(estimator = ada_boost_reg, X = X_train, y = y_train, cv = 10)\n",
    "print(f\"Accuracy: {accuracies.mean()*100}%\")\n",
    "print(f\"Standard Deviation: {accuracies.std()*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "With the most recent season (2020 at the time of this writing) stats, I am able to correctly pick the players that score 15+ pts about 65% of the time."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fda93764f742b83ee64d28c899e316dbaa873d0e3396a11189eda6319c8fd734"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
