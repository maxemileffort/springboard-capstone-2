{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51a5d508",
   "metadata": {},
   "source": [
    "# Recap and Goal Setting\n",
    "\n",
    "In the last notebook, we found that our method seems to work best when we filter out bad players first with the model that has the best results with choosing low scoring players (Gradient Boosting), followed by choosing players with a different model.\n",
    "\n",
    "After filtering, there were several models that performed well as far as choosing high scoring players goes. We want to see if we can improve the performance of those models even further, so that hopefully whenever the lineup builder goes to work, it doesn't take as long, and the lineups we end up with are much more likely to be high-scoring. \n",
    "\n",
    "Currently, out of 100 lineups built, only about 10-20% of them (depending on the model used) are actually \"in the money\" (ITM), or something that would see a return on an investment. In the long run, this is probably enough to break even, possibly even be profitable. But, a better percentage would shorten the time to a positive ROI, increase the ROI, or both.\n",
    "\n",
    "The other shortcoming right now: it takes about 70 min to generate these lineups. If a player is ruled out at the last minute, it wouldn't be feasible to try and re-run the current algorithm in it's current state with that player dropped, so speeding it up would be essential. I could probably just substitute a different predicted player in the position, but that subjects me to the emotions and other dubious pitfalls of picking players.\n",
    "\n",
    "So for this round, we have 2 goals:\n",
    "\n",
    "1. Reduce the time to build optimal lineups\n",
    "2. Increase the percentage of ITM lineups\n",
    "\n",
    "The goal is to implement Grid Search so that we filter players better, and after filtering, we choose players better. Those things in tandem should 1) make the pool smaller (speeds up lineup building) and 2) make the pool better representitive of high-scoring players (more ITM lineups)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0700799",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50451add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None # to remove some warnings\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OrdinalEncoder \n",
    "from sklearn.svm import SVR\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463dc94a",
   "metadata": {},
   "source": [
    "## Copied class from last notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9cacfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lineup:\n",
    "    \"\"\" \n",
    "    takes the results of the model prediction (dataframe \n",
    "    with attached predictions) and builds out a few lineups \n",
    "    \"\"\"\n",
    "    def __init__(self, df, def_df, verbose=False):\n",
    "        self.verbose = verbose\n",
    "        self.df = df\n",
    "        self.def_df = def_df[:15]\n",
    "        self.current_salary = 100*1000\n",
    "        self.no_duplicates = False\n",
    "        self.top_lineups = []\n",
    "        self.qbs = []\n",
    "        self.rbs = []\n",
    "        self.wrs = []\n",
    "        self.tes = []\n",
    "        self.flex = []\n",
    "        self.defs = []\n",
    "    \n",
    "    def find_top_10(self, position):\n",
    "        arr = []\n",
    "        end_of_range = len(self.df.loc[self.df['Pos']==position])\n",
    "        if position == 'Flex':\n",
    "            position_df = self.df.loc[(self.df['Pos']=='RB')|(self.df['Pos']=='TE')|(self.df['Pos']=='WR')]\n",
    "            end_of_range = (len(self.df.loc[self.df['Pos']=='RB'])+\n",
    "                            len(self.df.loc[self.df['Pos']=='WR'])+\n",
    "                            len(self.df.loc[self.df['Pos']=='TE']))\n",
    "        elif position == 'Def':\n",
    "            end_of_range = len(self.def_df)\n",
    "            position_df = self.def_df\n",
    "            position_df = position_df.sort_values(by='pred', ascending=False)\n",
    "        else:\n",
    "            position_df = self.df.loc[self.df['Pos']==position]\n",
    "        \n",
    "        # print(position_df)\n",
    "        for row in range(0,end_of_range):\n",
    "            player = {\n",
    "                'name': position_df.iloc[row]['Name'],\n",
    "                'h/a': position_df.iloc[row]['h/a'],\n",
    "                'pos': position_df.iloc[row]['Pos'],\n",
    "                'salary': position_df.iloc[row]['DK salary'],\n",
    "                'pred_points': position_df.iloc[row]['pred'],\n",
    "                'act_pts':position_df.iloc[row]['actual_score']\n",
    "            }\n",
    "            if len(arr) < end_of_range:\n",
    "                arr.append(player)\n",
    "            else: \n",
    "                break\n",
    "        return arr\n",
    "    \n",
    "    def get_players(self):\n",
    "        top_10_qbs = self.find_top_10(position='QB')\n",
    "        top_10_rbs = self.find_top_10(position='RB')\n",
    "        top_10_wrs = self.find_top_10(position='WR')\n",
    "        top_10_tes = self.find_top_10(position='TE')\n",
    "        top_10_flex = self.find_top_10(position='Flex')\n",
    "        top_10_defs = self.find_top_10(position='Def')\n",
    "        return top_10_qbs, top_10_rbs, top_10_wrs, top_10_tes, top_10_flex, top_10_defs\n",
    "    \n",
    "    def check_salary(self, lineup):\n",
    "        current_salary = 0\n",
    "        for keys in lineup.keys():\n",
    "            current_salary += lineup[keys]['salary']\n",
    "        return current_salary\n",
    "    \n",
    "    def reduce_salary(self, lineup):\n",
    "        while self.current_salary > 50*1000:\n",
    "            position_df = self.df\n",
    "            greatest_salary = 0\n",
    "            pos = 'none'\n",
    "            pos_to_change = 'none'\n",
    "            for key in lineup.keys():\n",
    "                if lineup[key]['salary'] > greatest_salary:\n",
    "                    greatest_salary = lineup[key]['salary']\n",
    "                    pos = lineup[key]['pos'] # RB, TE, Def, etc.\n",
    "                    pos_to_change = key # RB1 or WR2 or something like that\n",
    "            if pos_to_change == 'Def':\n",
    "                position_df = def_df\n",
    "            elif pos_to_change == 'Flex':\n",
    "                position_df = self.df.loc[(self.df['Pos']=='RB')|(self.df['Pos']=='TE')|(self.df['Pos']=='WR')]\n",
    "            else:\n",
    "                pass\n",
    "    #             print(position_df)    \n",
    "            new_player = (position_df.loc[(position_df.Pos == pos)&(position_df['DK salary'] < greatest_salary)]).sort_values(by='DK salary', ascending=False).head(1)\n",
    "            player = {\n",
    "                'name': new_player['Name'].values[0],\n",
    "                'h/a': new_player['h/a'].values[0],\n",
    "                'pos': new_player['Pos'].values[0],\n",
    "                'salary': new_player['DK salary'].values[0],\n",
    "                'pred_points': new_player['pred'].values[0],\n",
    "                'act_pts':new_player['actual_score'].values[0]\n",
    "            }\n",
    "    #         print(player)    \n",
    "            lineup[pos_to_change] = player\n",
    "    #         print(lineup)\n",
    "            self.current_salary = self.check_salary(lineup)\n",
    "        return lineup\n",
    "    \n",
    "    def check_duplicates(self, lineup):\n",
    "        rb1_name = lineup['RB1']['name']\n",
    "        rb2_name = lineup['RB2']['name']\n",
    "        flex_name = lineup['Flex']['name']\n",
    "        wr1_name = lineup['WR1']['name']\n",
    "        wr2_name = lineup['WR2']['name']\n",
    "        wr3_name = lineup['WR3']['name']\n",
    "        te_name = lineup['TE']['name']\n",
    "        names = [flex_name, rb1_name, rb2_name, wr1_name, wr2_name, wr3_name, te_name]\n",
    "        while len(names) > 1:\n",
    "            if names[0] in names[1:-1]:\n",
    "                return False\n",
    "            else:\n",
    "                names.pop(0)   \n",
    "        return True\n",
    "    \n",
    "    def shuffle_players(self):\n",
    "        lineup = {\n",
    "            'QB': self.qbs[random.randrange(len(self.df.loc[self.df['Pos']=='QB']))],\n",
    "            'RB1': self.rbs[random.randrange(len(self.df.loc[self.df['Pos']=='RB']))],\n",
    "            'RB2': self.rbs[random.randrange(len(self.df.loc[self.df['Pos']=='RB']))],\n",
    "            'WR1': self.wrs[random.randrange(len(self.df.loc[self.df['Pos']=='WR']))],\n",
    "            'WR2': self.wrs[random.randrange(len(self.df.loc[self.df['Pos']=='WR']))],\n",
    "            'WR3': self.wrs[random.randrange(len(self.df.loc[self.df['Pos']=='WR']))],\n",
    "            'TE': self.tes[random.randrange(len(self.df.loc[self.df['Pos']=='TE']))],\n",
    "            'Flex': self.flex[random.randrange(len(self.df.loc[self.df['Pos']=='RB'])+\n",
    "                                               len(self.df.loc[self.df['Pos']=='WR'])+\n",
    "                                               len(self.df.loc[self.df['Pos']=='TE']))],\n",
    "            'Def': self.defs[random.randrange(len(self.def_df))]\n",
    "        }\n",
    "        return lineup\n",
    "    \n",
    "    def build_lineup(self):\n",
    "        # in theory, because of the legwork done by the algorithm,\n",
    "        # any lineup should be good as long as it abides by the\n",
    "        # constraints of DraftKings' team structures. So for\n",
    "        # now, this will just give us the lineups that fit within\n",
    "        # the salary cap and team requirements\n",
    "        \n",
    "        self.current_salary = 100*1000\n",
    "        self.no_duplicates = False\n",
    "        self.qbs, self.rbs, self.wrs, self.tes, self.flex, self.defs = self.get_players()\n",
    "        lineup = self.shuffle_players()\n",
    "        \n",
    "        while True:\n",
    "            if self.verbose:\n",
    "                print('======================')\n",
    "                print(f\"Salary: {self.current_salary}\")\n",
    "                print(f\"No Duplicates: {self.no_duplicates}\")\n",
    "                print('======================')\n",
    "            self.no_duplicates = self.check_duplicates(lineup)\n",
    "            self.current_salary = self.check_salary(lineup)\n",
    "            # fix duplicates first\n",
    "            if self.no_duplicates == False:\n",
    "                lineup = self.shuffle_players()\n",
    "            # check salary, making sure it's between 45k and 50k\n",
    "            if self.current_salary > 50*1000:\n",
    "                try:\n",
    "                    lineup = self.reduce_salary(lineup)\n",
    "                except:\n",
    "                    lineup = self.shuffle_players()\n",
    "            self.no_duplicates = self.check_duplicates(lineup)\n",
    "            self.current_salary = self.check_salary(lineup)\n",
    "            \n",
    "            if (self.current_salary <= 50*1000 \n",
    "#             and self.current_salary >= 45*1000 \n",
    "            and self.no_duplicates):\n",
    "                # if everything looks good, end the \n",
    "                # loop and append the lineup\n",
    "                break\n",
    "                \n",
    "        \n",
    "        self.top_lineups.append(lineup)\n",
    "        if len(self.top_lineups) % 5 == 0:\n",
    "            print(f\"Added lineup. Total lineups: {len(self.top_lineups)}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14c5187",
   "metadata": {},
   "source": [
    "## Get and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c09dc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def get_weekly_data(week, year):\n",
    "    \"\"\" get player data for designated week \"\"\"\n",
    "    file_path = f\"./csv's/{year}/year-{year}-week-{week}-DK-player_data.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "def get_ytd_season_data(year, current_week):\n",
    "    \"\"\" get data for current season up to most recent week \"\"\"\n",
    "    df = get_weekly_data(1,year)\n",
    "    for week in range(2,current_week+1):\n",
    "        try:\n",
    "            df = df.append(get_weekly_data(week, year), ignore_index=True)\n",
    "        except:\n",
    "            print(\"No data for week: \"+str(week))\n",
    "    df = df.drop(['Unnamed: 0', 'Year'], axis=1)\n",
    "    return df\n",
    "\n",
    "def get_season_data(year, drop_year=True):\n",
    "    \"\"\" get entire season of data \"\"\"\n",
    "    df = get_weekly_data(1,year)\n",
    "    for week in range(2,17):\n",
    "        try:\n",
    "            df = df.append(get_weekly_data(week, year), ignore_index=True)\n",
    "        except:\n",
    "            print(\"No data for week: \"+str(week))\n",
    "    if drop_year:\n",
    "        df = df.drop(['Unnamed: 0', 'Year'], axis=1)\n",
    "    else:\n",
    "        df = df.drop(['Unnamed: 0'], axis=1)\n",
    "    return df\n",
    "\n",
    "def scale_features(sc_salary, sc_points, sc_pts_ald, X_train, X_test, first_time=False):\n",
    "    \"\"\" scales data for training \"\"\"\n",
    "    if first_time:\n",
    "        X_train['DK salary'] = sc_salary.fit_transform(X_train['DK salary'].values.reshape(-1,1))\n",
    "#         X_train['Oppt_pts_allowed_lw'] = sc_pts_ald.fit_transform(X_train['Oppt_pts_allowed_lw'].values.reshape(-1,1))\n",
    "    X_test['DK salary'] = sc_salary.transform(X_test['DK salary'].values.reshape(-1,1))\n",
    "#     X_test['Oppt_pts_allowed_lw'] = sc_pts_ald.transform(X_test['Oppt_pts_allowed_lw'].values.reshape(-1,1))\n",
    "    return X_train, X_test\n",
    "\n",
    "def unscale_features(sc_salary, sc_points, sc_pts_ald, X_train, X_test):\n",
    "    \"\"\" used to change features back so that human readable information can be used to assess\n",
    "    lineups and player information and performance\"\"\"\n",
    "    X_train['DK salary'] = sc_salary.inverse_transform(X_train['DK salary'].values.reshape(-1,1))\n",
    "#     X_train['Oppt_pts_allowed_lw'] = sc_pts_ald.inverse_transform(X_train['Oppt_pts_allowed_lw'].values.reshape(-1,1))\n",
    "    X_test['DK salary'] = sc_salary.inverse_transform(X_test['DK salary'].values.reshape(-1,1))\n",
    "#     X_test['avg_points'] = sc_points.inverse_transform(X_test['avg_points'].values.reshape(-1,1))\n",
    "#     X_test['Oppt_pts_allowed_lw'] = sc_pts_ald.inverse_transform(X_test['Oppt_pts_allowed_lw'].values.reshape(-1,1))\n",
    "    return X_train, X_test\n",
    "\n",
    "def handle_nulls(df):\n",
    "    # players that have nulls for any of the columns are \n",
    "    # extremely likely to be under performing or going into a bye.\n",
    "    # the one caveat is that some are possibly coming off a bye.\n",
    "    # to handle this later, probably will drop them, save those\n",
    "    # as a variable, and then re-merge after getting rid of the other\n",
    "    # null values.\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "def eval_model(df):\n",
    "    df['score_ratio'] = round(df['actual_score'] / df['pred'],4)\n",
    "    return df\n",
    "\n",
    "def remove_outliers_btwn_ij(df, i=-1, j=5):\n",
    "    s = df.loc[(df.score_ratio > i) & (df.score_ratio < j)]\n",
    "    return s, i, j\n",
    "\n",
    "def get_RMSE(y_true, y_pred):\n",
    "    MSE = mean_squared_error(y_true, y_pred)\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    return RMSE\n",
    "\n",
    "def summarize_df(df, o_u_thresh=15):\n",
    "    df = eval_model(df)\n",
    "    RMSE = get_RMSE(df['actual_score'], df['pred'])\n",
    "    print(f\"Total entries analyzed: {len(df)}\")\n",
    "    s, i, j = remove_outliers_btwn_ij(df)\n",
    "    print(f\"Total entries after outliers removed: {len(s)}. Left boundary: {i}x Right Boundary: {j}x\")\n",
    "    correct_preds_over_thresh = s[(s.pred >= o_u_thresh)&(s.actual_score>=o_u_thresh)]\n",
    "    correct_preds_under_thresh = s[(s.pred <= o_u_thresh)&(s.actual_score<=o_u_thresh)]\n",
    "    incorrect_preds_under_thresh = s[(s.pred <= o_u_thresh)&(s.actual_score>=o_u_thresh)]\n",
    "    incorrect_preds_over_thresh = s[(s.pred >= o_u_thresh)&(s.actual_score<=o_u_thresh)]\n",
    "    print(f\"Correct predictions of over {o_u_thresh} pts: {len(correct_preds_over_thresh)}. Percent: {round(len(correct_preds_over_thresh)/len(s)*100,2)}\") # True Positive\n",
    "    print(f\"Correct predictions of under {o_u_thresh} pts: {len(correct_preds_under_thresh)}. Percent: {round(len(correct_preds_under_thresh)/len(s)*100,2)}\") # True Negative\n",
    "    print(f\"Incorrect predictions of over {o_u_thresh} pts: {len(incorrect_preds_over_thresh)}. Percent: {round(len(incorrect_preds_over_thresh)/len(s)*100,2)}\") # False Positive\n",
    "    print(f\"Incorrect predictions of under {o_u_thresh} pts: {len(incorrect_preds_under_thresh)}. Percent: {round(len(incorrect_preds_under_thresh)/len(s)*100,2)}\") # False Negative\n",
    "    print(f\"RMSE: {RMSE}\")\n",
    "    print(\"Ignore following metrics for filtered DF:\")\n",
    "    print(f\"Total percent correct over {o_u_thresh}: {round(len(correct_preds_over_thresh)/len(s)*100,2)-round(len(incorrect_preds_over_thresh)/len(s)*100,2)}\")\n",
    "    print(f\"Total percent correct under {o_u_thresh}: {round(len(correct_preds_under_thresh)/len(s)*100,2)-round(len(incorrect_preds_under_thresh)/len(s)*100,2)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d53c78ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "season = 2020\n",
    "week = 6\n",
    "next_week = week + 1\n",
    "dataset = get_season_data(season)\n",
    "df = handle_nulls(dataset)\n",
    "def_df = df.loc[df.Pos == 'Def']\n",
    "def_df['fantasy_points_allowed_lw'] = 0\n",
    "df['Oppt_pts_allowed_lw'] = 0\n",
    "def_teams = [x for x in def_df['Team'].unique()]\n",
    "\n",
    "for week in range(1,17):\n",
    "    for team in def_teams:\n",
    "        try:\n",
    "            offense_df1 = df.loc[(df['Oppt']==team)&(df['Week']==week)]\n",
    "            offense_df2 = df.loc[(df['Oppt']==team)&(df['Week']==week+1)]\n",
    "            sum_ = offense_df1['DK points'].sum()\n",
    "            def_df.loc[(df['Team']==team)&(df['Week']==week+1), 'fantasy_points_allowed_lw'] = sum_\n",
    "            df.loc[(df['Oppt']==team)&(df['Week']==week+1), 'Oppt_pts_allowed_lw'] = sum_\n",
    "        except:\n",
    "            print('couldnt append data')\n",
    "            pass\n",
    "df = df[df.Week != 1] \n",
    "X = df.drop(labels='DK points', axis=1)\n",
    "y = df['DK points']\n",
    "X2 = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1222a2fe",
   "metadata": {},
   "source": [
    "## Grid searches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce328fb4",
   "metadata": {},
   "source": [
    "### Algorithms to Grid Search: Ada Boost, Random Forest, Ridge, XGBoost, & Support Vector Regression (rbf kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d72e31aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_names = ['Ridge', 'Gradient Boosting', 'AdaBoost', 'Random Forest', 'XGBoost', 'SVR']\n",
    "grid_searches = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b05658d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 15min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gamma_range = [1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,1e0,1e1]\n",
    "c_range = [1e-3,1e-2,1e-1,1e0,1e1,1e2,1e3,1e4,1e5]\n",
    "svr_param_grid = {\n",
    "    'kernel' : ('rbf', 'sigmoid'),\n",
    "    'C' : c_range,\n",
    "    'gamma' : gamma_range\n",
    "}\n",
    "svr = SVR()\n",
    "svr_cv = GridSearchCV(svr,svr_param_grid,cv=3,n_jobs=3)\n",
    "svr_cv.fit(X2,y)\n",
    "grid_searches.append({'name': 'SVR', 'search': svr_cv})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "603078bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "append() takes exactly one argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: append() takes exactly one argument (0 given)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ridge_param_grid = {\n",
    "    'alpha': [1,0.1,0.01,0.001,0.0001,0] , \n",
    "    \"fit_intercept\": [True, False], \n",
    "    \"solver\": ['svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "}\n",
    "ridge = Ridge()\n",
    "ridge_cv = GridSearchCV(ridge,ridge_param_grid,cv=3,n_jobs=3)\n",
    "ridge_cv.fit(X2,y)\n",
    "grid_searches.append({'name': 'Ridge', 'search': ridge_cv})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6ffc9f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gb_param_grid = {\n",
    "#     'n_estimators':[100,300,500], # default of 100 was consistenly the best for several tests\n",
    "    'learning_rate': [0.1,0.05,0.02],\n",
    "    'max_depth':[3,4,5,6], \n",
    "    'min_samples_leaf':[1,2,3], \n",
    "    'max_features':('auto', 'sqrt', 'log2')\n",
    "}\n",
    "gb = GradientBoostingRegressor()\n",
    "gb_cv = GridSearchCV(gb,gb_param_grid,cv=3,n_jobs=3)\n",
    "gb_cv.fit(X2,y)\n",
    "grid_searches.append({'name': 'Gradient Boost', 'search': gb_cv})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52a230f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 53min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ab_param_grid = {\n",
    "    'n_estimators':[100,500,1000], \n",
    "    'learning_rate': [0.1,0.05,0.02],\n",
    "    'loss': ('linear', 'square', 'exponential')\n",
    "}\n",
    "ab = AdaBoostRegressor()\n",
    "ab_cv = GridSearchCV(ab,ab_param_grid,cv=3,n_jobs=3)\n",
    "ab_cv.fit(X2,y)\n",
    "grid_searches.append({'name': 'AdaBoost', 'search': ab_cv})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0877974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_param_grid = {\n",
    "    'n_estimators':[100,300,500,1000], \n",
    "    'max_depth':[3,4,5,6], \n",
    "    'min_samples_leaf':[1,2,3],  \n",
    "    'max_features':('auto', 'sqrt', 'log2')\n",
    "}\n",
    "rf = RandomForestRegressor()\n",
    "rf_cv = GridSearchCV(rf,rf_param_grid,cv=3,n_jobs=3)\n",
    "rf_cv.fit(X2,y)\n",
    "grid_searches.append({'name': 'Random Forest', 'search': rf_cv})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "737e1a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:05:45] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { loss } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Wall time: 38min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_param_grid = {\n",
    "    'n_estimators':[100,500,1000], \n",
    "    'learning_rate': [0.1,0.05,0.02],\n",
    "    'loss': ('linear', 'square', 'exponential')\n",
    "}\n",
    "xgb = XGBRegressor()\n",
    "xgb_cv = GridSearchCV(xgb,xgb_param_grid,cv=3,n_jobs=3)\n",
    "xgb_cv.fit(X2,y)\n",
    "grid_searches.append({'name': 'XGBoost', 'search': xgb_cv})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d8565bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: SVR\n",
      "Best Score: 0.3667398920100726\n",
      "Best Parameters: {'C': 100000.0, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "======================================================\n",
      "Grid Search: Ridge\n",
      "Best Score: 0.4064692035835569\n",
      "Best Parameters: {'alpha': 1, 'fit_intercept': True, 'solver': 'svd'}\n",
      "======================================================\n",
      "Grid Search: Gradient Boost\n",
      "Best Score: 0.4224293893546227\n",
      "Best Parameters: {'learning_rate': 0.05, 'max_depth': 3, 'max_features': 'auto', 'min_samples_leaf': 2}\n",
      "======================================================\n",
      "Grid Search: AdaBoost\n",
      "Best Score: 0.401264002451922\n",
      "Best Parameters: {'learning_rate': 0.02, 'loss': 'exponential', 'n_estimators': 100}\n",
      "======================================================\n",
      "Grid Search: Random Forest\n",
      "Best Score: 0.4323875239294619\n",
      "Best Parameters: {'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 3, 'n_estimators': 300}\n",
      "======================================================\n",
      "Grid Search: XGBoost\n",
      "Best Score: 0.4118071249462032\n",
      "Best Parameters: {'learning_rate': 0.05, 'loss': 'linear', 'n_estimators': 100}\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "for s in grid_searches:\n",
    "    print(f\"Grid Search: {s['name']}\")\n",
    "    print(\"Best Score: \" + str(s['search'].best_score_))\n",
    "    print(\"Best Parameters: \" + str(s['search'].best_params_))\n",
    "    print(\"======================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b377ee9",
   "metadata": {},
   "source": [
    "## CV metrics from the regression notebook: \n",
    "\n",
    "- model name: ridge_reg\n",
    "- R2: 0.41466767899168466\n",
    "- new R2: 0.4064692035835569\n",
    "---\n",
    "- model name: svr1_reg (linear kernel)\n",
    "- R2: -0.6560443491554244\n",
    "---\n",
    "- model name: svr2_reg (rbf kernel)\n",
    "- R2: 0.3436414633993596\n",
    "- new R2: 0.3667398920100726\n",
    "---\n",
    "- model name: random_forest_reg\n",
    "- R2: 0.37988667548813754\n",
    "- new R2: 0.4323875239294619\n",
    "---\n",
    "- model name: ada_boost_reg\n",
    "- R2: -0.14535859319297745\n",
    "- new R2: 0.401264002451922\n",
    "---\n",
    "- model name: gradient_boost_reg\n",
    "- R2: 0.41595907588432846\n",
    "- new R2: 0.4224293893546227\n",
    "---\n",
    "- model name: xgb_reg\n",
    "- R2: 0.3757455851440273\n",
    "- new R2: 0.4118071249462032\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e7d7e1",
   "metadata": {},
   "source": [
    "So all of the accuracies got better except one: Ridge regression. In theory that means it will do worse, but the diffence between accuracies is minimal, so I'd like to see what the performance of it is.\n",
    "\n",
    "Adaboost saw a HUGE improvement, which is interesting, as it's already the best model used to pick players after filtering.\n",
    "\n",
    "Next, we'll try just using one model to pick players and see the new results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d136338",
   "metadata": {},
   "source": [
    "## Re-train new, tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "999b8286",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fc90243",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg = Ridge(**[s['search'].best_params_ for s in grid_searches if s['name']=='Ridge'][0])\n",
    "svr_reg = SVR(**[s['search'].best_params_ for s in grid_searches if s['name']=='SVR'][0])\n",
    "rf_reg = RandomForestRegressor(**[s['search'].best_params_ for s in grid_searches if s['name']=='Random Forest'][0])\n",
    "ab_reg = AdaBoostRegressor(**[s['search'].best_params_ for s in grid_searches if s['name']=='AdaBoost'][0]) \n",
    "gb_reg = GradientBoostingRegressor(**[s['search'].best_params_ for s in grid_searches if s['name']=='Gradient Boost'][0])\n",
    "xgb_reg = XGBRegressor(**[s['search'].best_params_ for s in grid_searches if s['name']=='XGBoost'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ccfe9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:24:16] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { loss } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.05, loss='linear', max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_reg.fit(X_train, y_train)\n",
    "svr_reg.fit(X_train, y_train)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "ab_reg.fit(X_train, y_train)\n",
    "gb_reg.fit(X_train, y_train)\n",
    "xgb_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0406aade",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = ridge_reg.predict(X_test)\n",
    "y_pred2 = svr_reg.predict(X_test)\n",
    "y_pred3 = rf_reg.predict(X_test)\n",
    "y_pred4 = ab_reg.predict(X_test)\n",
    "y_pred5 = gb_reg.predict(X_test)\n",
    "y_pred6 = xgb_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c60288f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.635322748793196,\n",
       " 6.9486001509233075,\n",
       " 6.6075320548750796,\n",
       " 6.720340025829452,\n",
       " 6.592370052275926,\n",
       " 6.59784825206268]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = [get_RMSE(y_test, y_pred1), \n",
    "          get_RMSE(y_test, y_pred2), \n",
    "          get_RMSE(y_test, y_pred3), \n",
    "          get_RMSE(y_test, y_pred4), \n",
    "          get_RMSE(y_test, y_pred5), \n",
    "          get_RMSE(y_test, y_pred6)]\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e103422",
   "metadata": {},
   "source": [
    "## Rebuild Lineup Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f4f38b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_for_lineups' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-757fc128c482>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlineup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLineup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_for_lineups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdef_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_for_lineups' is not defined"
     ]
    }
   ],
   "source": [
    "lineup = Lineup(df_for_lineups, def_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42d6c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# this step takes a while\n",
    "for x in range (0,100):\n",
    "    lineup.build_lineup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
