{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b117cdf5",
   "metadata": {},
   "source": [
    "# Final Predictions\n",
    "\n",
    "After our grid search, we saw that the combination of Gradient Boost / AdaBoost was still the best option. \n",
    "\n",
    "While we weren't able to build a model that lends itself well to tournament play, we did find some that look to do ok with double up and 50/50 play.\n",
    "\n",
    "This notebook is going to, initially, just do predictions for previous seasons.\n",
    "\n",
    "Later I hope to use it to generate a player pool for building lineups, with the hopes of eventually completely automating that all together.\n",
    "\n",
    "Just scroll down to where it says \"Start Here\" and have some fun with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98178f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None # to remove some warnings\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OrdinalEncoder \n",
    "from sklearn.svm import SVR\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c285a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lineup:\n",
    "    \"\"\" \n",
    "    takes the results of the model prediction (dataframe \n",
    "    with attached predictions) and builds out a few lineups \n",
    "    \"\"\"\n",
    "    def __init__(self, df, def_df, verbose=False):\n",
    "        self.verbose = verbose\n",
    "        self.df = df\n",
    "        self.def_df = def_df[:15]\n",
    "        self.current_salary = 100*1000\n",
    "        self.no_duplicates = False\n",
    "        self.top_lineups = []\n",
    "        self.qbs = []\n",
    "        self.rbs = []\n",
    "        self.wrs = []\n",
    "        self.tes = []\n",
    "        self.flex = []\n",
    "        self.defs = []\n",
    "    \n",
    "    def find_top_10(self, position):\n",
    "        arr = []\n",
    "        end_of_range = len(self.df.loc[self.df['Pos']==position])\n",
    "        if position == 'Flex':\n",
    "            position_df = self.df.loc[(self.df['Pos']=='RB')|(self.df['Pos']=='TE')|(self.df['Pos']=='WR')]\n",
    "            end_of_range = (len(self.df.loc[self.df['Pos']=='RB'])+\n",
    "                            len(self.df.loc[self.df['Pos']=='WR'])+\n",
    "                            len(self.df.loc[self.df['Pos']=='TE']))\n",
    "        elif position == 'Def':\n",
    "            end_of_range = len(self.def_df)\n",
    "            position_df = self.def_df\n",
    "            position_df = position_df.sort_values(by='pred', ascending=False)\n",
    "        else:\n",
    "            position_df = self.df.loc[self.df['Pos']==position]\n",
    "        \n",
    "        # print(position_df)\n",
    "        for row in range(0,end_of_range):\n",
    "            player = {\n",
    "                'name': position_df.iloc[row]['Name'],\n",
    "                'h/a': position_df.iloc[row]['h/a'],\n",
    "                'pos': position_df.iloc[row]['Pos'],\n",
    "                'salary': position_df.iloc[row]['DK salary'],\n",
    "                'pred_points': position_df.iloc[row]['pred'],\n",
    "                'act_pts':position_df.iloc[row]['actual_score']\n",
    "            }\n",
    "            if len(arr) < end_of_range:\n",
    "                arr.append(player)\n",
    "            else: \n",
    "                break\n",
    "        return arr\n",
    "    \n",
    "    def get_players(self):\n",
    "        top_10_qbs = self.find_top_10(position='QB')\n",
    "        top_10_rbs = self.find_top_10(position='RB')\n",
    "        top_10_wrs = self.find_top_10(position='WR')\n",
    "        top_10_tes = self.find_top_10(position='TE')\n",
    "        top_10_flex = self.find_top_10(position='Flex')\n",
    "        top_10_defs = self.find_top_10(position='Def')\n",
    "        return top_10_qbs, top_10_rbs, top_10_wrs, top_10_tes, top_10_flex, top_10_defs\n",
    "    \n",
    "    def check_salary(self, lineup):\n",
    "        current_salary = 0\n",
    "        for keys in lineup.keys():\n",
    "            current_salary += lineup[keys]['salary']\n",
    "        return current_salary\n",
    "    \n",
    "    def reduce_salary(self, lineup):\n",
    "        while self.current_salary > 50*1000:\n",
    "            position_df = self.df\n",
    "            greatest_salary = 0\n",
    "            pos = 'none'\n",
    "            pos_to_change = 'none'\n",
    "            for key in lineup.keys():\n",
    "                if lineup[key]['salary'] > greatest_salary:\n",
    "                    greatest_salary = lineup[key]['salary']\n",
    "                    pos = lineup[key]['pos'] # RB, TE, Def, etc.\n",
    "                    pos_to_change = key # RB1 or WR2 or something like that\n",
    "            if pos_to_change == 'Def':\n",
    "                position_df = def_df\n",
    "            elif pos_to_change == 'Flex':\n",
    "                position_df = self.df.loc[(self.df['Pos']=='RB')|(self.df['Pos']=='TE')|(self.df['Pos']=='WR')]\n",
    "            else:\n",
    "                pass\n",
    "    #             print(position_df)    \n",
    "            new_player = (position_df.loc[(position_df.Pos == pos)&(position_df['DK salary'] < greatest_salary)]).sort_values(by='DK salary', ascending=False).head(1)\n",
    "            player = {\n",
    "                'name': new_player['Name'].values[0],\n",
    "                'h/a': new_player['h/a'].values[0],\n",
    "                'pos': new_player['Pos'].values[0],\n",
    "                'salary': new_player['DK salary'].values[0],\n",
    "                'pred_points': new_player['pred'].values[0],\n",
    "                'act_pts':new_player['actual_score'].values[0]\n",
    "            }\n",
    "    #         print(player)    \n",
    "            lineup[pos_to_change] = player\n",
    "    #         print(lineup)\n",
    "            self.current_salary = self.check_salary(lineup)\n",
    "        return lineup\n",
    "    \n",
    "    def check_duplicates(self, lineup):\n",
    "        rb1_name = lineup['RB1']['name']\n",
    "        rb2_name = lineup['RB2']['name']\n",
    "        flex_name = lineup['Flex']['name']\n",
    "        wr1_name = lineup['WR1']['name']\n",
    "        wr2_name = lineup['WR2']['name']\n",
    "        wr3_name = lineup['WR3']['name']\n",
    "        te_name = lineup['TE']['name']\n",
    "        names = [flex_name, rb1_name, rb2_name, wr1_name, wr2_name, wr3_name, te_name]\n",
    "        while len(names) > 1:\n",
    "            if names[0] in names[1:-1]:\n",
    "                return False\n",
    "            else:\n",
    "                names.pop(0)   \n",
    "        return True\n",
    "    \n",
    "    def shuffle_players(self):\n",
    "        lineup = {\n",
    "            'QB': self.qbs[random.randrange(len(self.df.loc[self.df['Pos']=='QB']))],\n",
    "            'RB1': self.rbs[random.randrange(len(self.df.loc[self.df['Pos']=='RB']))],\n",
    "            'RB2': self.rbs[random.randrange(len(self.df.loc[self.df['Pos']=='RB']))],\n",
    "            'WR1': self.wrs[random.randrange(len(self.df.loc[self.df['Pos']=='WR']))],\n",
    "            'WR2': self.wrs[random.randrange(len(self.df.loc[self.df['Pos']=='WR']))],\n",
    "            'WR3': self.wrs[random.randrange(len(self.df.loc[self.df['Pos']=='WR']))],\n",
    "            'TE': self.tes[random.randrange(len(self.df.loc[self.df['Pos']=='TE']))],\n",
    "            'Flex': self.flex[random.randrange(len(self.df.loc[self.df['Pos']=='RB'])+\n",
    "                                               len(self.df.loc[self.df['Pos']=='WR'])+\n",
    "                                               len(self.df.loc[self.df['Pos']=='TE']))],\n",
    "            'Def': self.defs[random.randrange(len(self.def_df))]\n",
    "        }\n",
    "        return lineup\n",
    "    \n",
    "    def build_lineup(self,verbose=False):\n",
    "        # in theory, because of the legwork done by the algorithm,\n",
    "        # any lineup should be good as long as it abides by the\n",
    "        # constraints of DraftKings' team structures. So for\n",
    "        # now, this will just give us the lineups that fit within\n",
    "        # the salary cap and team requirements\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        self.current_salary = 100*1000\n",
    "        self.no_duplicates = False\n",
    "        if len(self.qbs) < 1:\n",
    "            self.qbs, self.rbs, self.wrs, self.tes, self.flex, self.defs = self.get_players()\n",
    "        lineup = self.shuffle_players()\n",
    "        \n",
    "        while True:\n",
    "            if self.verbose:\n",
    "                print('======================')\n",
    "                print(f\"Salary: {self.current_salary}\")\n",
    "                print(f\"No Duplicates: {self.no_duplicates}\")\n",
    "                print('======================')\n",
    "            self.no_duplicates = self.check_duplicates(lineup)\n",
    "            self.current_salary = self.check_salary(lineup)\n",
    "            # fix duplicates first\n",
    "            if self.no_duplicates == False:\n",
    "                lineup = self.shuffle_players()\n",
    "            # check salary, making sure it's between 45k and 50k\n",
    "            if self.current_salary > 50*1000:\n",
    "                try:\n",
    "                    lineup = self.reduce_salary(lineup)\n",
    "                except:\n",
    "                    lineup = self.shuffle_players()\n",
    "            self.no_duplicates = self.check_duplicates(lineup)\n",
    "            self.current_salary = self.check_salary(lineup)\n",
    "            \n",
    "            if (self.current_salary <= 50*1000 \n",
    "#             and self.current_salary >= 45*1000 \n",
    "            and self.no_duplicates):\n",
    "                # if everything looks good, end the \n",
    "                # loop and append the lineup\n",
    "                break\n",
    "                \n",
    "        \n",
    "        self.top_lineups.append(lineup)\n",
    "        if len(self.top_lineups) % 5 == 0:\n",
    "            print(f\"Added lineup. Total lineups: {len(self.top_lineups)}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c8e6452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def get_weekly_data(week, year):\n",
    "    \"\"\" get player data for designated week \"\"\"\n",
    "    file_path = f\"./csv's/{year}/year-{year}-week-{week}-DK-player_data.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "def get_ytd_season_data(year, current_week):\n",
    "    \"\"\" get data for current season up to most recent week \"\"\"\n",
    "    df = get_weekly_data(1,year)\n",
    "    for week in range(2,current_week+1):\n",
    "        try:\n",
    "            df = df.append(get_weekly_data(week, year), ignore_index=True)\n",
    "        except:\n",
    "            print(\"No data for week: \"+str(week))\n",
    "    df = df.drop(['Unnamed: 0', 'Year'], axis=1)\n",
    "    return df\n",
    "\n",
    "def get_season_data(year, drop_year=True):\n",
    "    \"\"\" get entire season of data \"\"\"\n",
    "    df = get_weekly_data(1,year)\n",
    "    for week in range(2,17):\n",
    "        try:\n",
    "            df = df.append(get_weekly_data(week, year), ignore_index=True)\n",
    "        except:\n",
    "            print(\"No data for week: \"+str(week))\n",
    "    if drop_year:\n",
    "        df = df.drop(['Unnamed: 0', 'Year'], axis=1)\n",
    "    else:\n",
    "        df = df.drop(['Unnamed: 0'], axis=1)\n",
    "    return df\n",
    "\n",
    "def scale_features(sc_salary, sc_points, sc_pts_ald, X_train, X_test, first_time=False):\n",
    "    \"\"\" scales data for training \"\"\"\n",
    "    if first_time:\n",
    "        X_train['DK salary'] = sc_salary.fit_transform(X_train['DK salary'].values.reshape(-1,1))\n",
    "#         X_train['Oppt_pts_allowed_lw'] = sc_pts_ald.fit_transform(X_train['Oppt_pts_allowed_lw'].values.reshape(-1,1))\n",
    "    X_test['DK salary'] = sc_salary.transform(X_test['DK salary'].values.reshape(-1,1))\n",
    "#     X_test['Oppt_pts_allowed_lw'] = sc_pts_ald.transform(X_test['Oppt_pts_allowed_lw'].values.reshape(-1,1))\n",
    "    return X_train, X_test\n",
    "\n",
    "def unscale_features(sc_salary, sc_points, sc_pts_ald, X_train, X_test):\n",
    "    \"\"\" used to change features back so that human readable information can be used to assess\n",
    "    lineups and player information and performance\"\"\"\n",
    "    X_train['DK salary'] = sc_salary.inverse_transform(X_train['DK salary'].values.reshape(-1,1))\n",
    "#     X_train['Oppt_pts_allowed_lw'] = sc_pts_ald.inverse_transform(X_train['Oppt_pts_allowed_lw'].values.reshape(-1,1))\n",
    "    X_test['DK salary'] = sc_salary.inverse_transform(X_test['DK salary'].values.reshape(-1,1))\n",
    "#     X_test['avg_points'] = sc_points.inverse_transform(X_test['avg_points'].values.reshape(-1,1))\n",
    "#     X_test['Oppt_pts_allowed_lw'] = sc_pts_ald.inverse_transform(X_test['Oppt_pts_allowed_lw'].values.reshape(-1,1))\n",
    "    return X_train, X_test\n",
    "\n",
    "def handle_nulls(df):\n",
    "    # players that have nulls for any of the columns are \n",
    "    # extremely likely to be under performing or going into a bye.\n",
    "    # the one caveat is that some are possibly coming off a bye.\n",
    "    # to handle this later, probably will drop them, save those\n",
    "    # as a variable, and then re-merge after getting rid of the other\n",
    "    # null values.\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "def eval_model(df):\n",
    "    df['score_ratio'] = round(df['actual_score'] / df['pred'],4)\n",
    "    return df\n",
    "\n",
    "def remove_outliers_btwn_ij(df, i=-1, j=5):\n",
    "    s = df.loc[(df.score_ratio > i) & (df.score_ratio < j)]\n",
    "    return s, i, j\n",
    "\n",
    "def get_RMSE(y_true, y_pred):\n",
    "    MSE = mean_squared_error(y_true, y_pred)\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    return RMSE\n",
    "\n",
    "def summarize_df(df, o_u_thresh=15):\n",
    "    df = eval_model(df)\n",
    "    RMSE = get_RMSE(df['actual_score'], df['pred'])\n",
    "    print(f\"Total entries analyzed: {len(df)}\")\n",
    "    s, i, j = remove_outliers_btwn_ij(df)\n",
    "    print(f\"Total entries after outliers removed: {len(s)}. Left boundary: {i}x Right Boundary: {j}x\")\n",
    "    correct_preds_over_thresh = s[(s.pred >= o_u_thresh)&(s.actual_score>=o_u_thresh)]\n",
    "    correct_preds_under_thresh = s[(s.pred <= o_u_thresh)&(s.actual_score<=o_u_thresh)]\n",
    "    incorrect_preds_under_thresh = s[(s.pred <= o_u_thresh)&(s.actual_score>=o_u_thresh)]\n",
    "    incorrect_preds_over_thresh = s[(s.pred >= o_u_thresh)&(s.actual_score<=o_u_thresh)]\n",
    "    print(f\"Correct predictions of over {o_u_thresh} pts: {len(correct_preds_over_thresh)}. Percent: {round(len(correct_preds_over_thresh)/len(s)*100,2)}\") # True Positive\n",
    "    print(f\"Correct predictions of under {o_u_thresh} pts: {len(correct_preds_under_thresh)}. Percent: {round(len(correct_preds_under_thresh)/len(s)*100,2)}\") # True Negative\n",
    "    print(f\"Incorrect predictions of over {o_u_thresh} pts: {len(incorrect_preds_over_thresh)}. Percent: {round(len(incorrect_preds_over_thresh)/len(s)*100,2)}\") # False Positive\n",
    "    print(f\"Incorrect predictions of under {o_u_thresh} pts: {len(incorrect_preds_under_thresh)}. Percent: {round(len(incorrect_preds_under_thresh)/len(s)*100,2)}\") # False Negative\n",
    "    print(f\"RMSE: {RMSE}\")\n",
    "    print(\"Ignore following metrics for filtered DF:\")\n",
    "    print(f\"Total percent correct over {o_u_thresh}: {round(len(correct_preds_over_thresh)/len(s)*100,2)-round(len(incorrect_preds_over_thresh)/len(s)*100,2)}\")\n",
    "    print(f\"Total percent correct under {o_u_thresh}: {round(len(correct_preds_under_thresh)/len(s)*100,2)-round(len(incorrect_preds_under_thresh)/len(s)*100,2)}\")\n",
    "\n",
    "def invert_one_hot_encode(df, cols=None, sub_strs=None):\n",
    "    df['Name'] = (df.iloc[:, 3:len(df)] == 1).idxmax(1).str.replace('Name_', \"\")\n",
    "    subset = ['Week', 'DK salary', 'Oppt_pts_allowed_lw', 'Name']\n",
    "    new_df = df[subset]\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606e66c2",
   "metadata": {},
   "source": [
    "# Start Here\n",
    "\n",
    "Just type in a season, and a week, run the notebook, and watch the results at the end!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdb54e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "season = 2020\n",
    "week = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbc70d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_week = week + 1\n",
    "dataset = get_season_data(season)\n",
    "df = handle_nulls(dataset)\n",
    "def_df = df.loc[df.Pos == 'Def']\n",
    "def_df['fantasy_points_allowed_lw'] = 0\n",
    "df['Oppt_pts_allowed_lw'] = 0\n",
    "def_teams = [x for x in def_df['Team'].unique()]\n",
    "\n",
    "def_df['pred'] = 1\n",
    "def_df = def_df.rename(columns={'DK points': 'actual_score'})\n",
    "def_df\n",
    "\n",
    "for week in range(1,17):\n",
    "    for team in def_teams:\n",
    "        try:\n",
    "            offense_df1 = df.loc[(df['Oppt']==team)&(df['Week']==week)]\n",
    "            offense_df2 = df.loc[(df['Oppt']==team)&(df['Week']==week+1)]\n",
    "            sum_ = offense_df1['DK points'].sum()\n",
    "            def_df.loc[(df['Team']==team)&(df['Week']==week+1), 'fantasy_points_allowed_lw'] = sum_\n",
    "            df.loc[(df['Oppt']==team)&(df['Week']==week+1), 'Oppt_pts_allowed_lw'] = sum_\n",
    "        except:\n",
    "            print('couldnt append data')\n",
    "            pass\n",
    "df = df[df.Week != 1] \n",
    "X = df.drop(labels='DK points', axis=1)\n",
    "y = df['DK points']\n",
    "X2 = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4bdbbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d58ee5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.05, max_features='auto',\n",
       "                          min_samples_leaf=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_reg = AdaBoostRegressor(**{'learning_rate': 0.02, \n",
    "                              'loss': 'exponential', \n",
    "                              'n_estimators': 100}) \n",
    "gb_reg = GradientBoostingRegressor(**{'learning_rate': 0.05, \n",
    "                                      'max_depth': 3, \n",
    "                                      'max_features': 'auto', \n",
    "                                      'min_samples_leaf': 2})\n",
    "ab_reg.fit(X_train, y_train)\n",
    "gb_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e036f222",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gb_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae1d2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['pred'] = y_pred\n",
    "\n",
    "df_filtered = X_test.loc[X_test['pred']>=15]\n",
    "\n",
    "X_test = X_test.drop(columns='pred')\n",
    "df_filtered = df_filtered.drop(columns='pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f8da2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ab_reg.predict(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21c271b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_df = invert_one_hot_encode(df_filtered)\n",
    "inverted_df['pred'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efec4aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>DK salary</th>\n",
       "      <th>Oppt_pts_allowed_lw</th>\n",
       "      <th>Name</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>2</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>88.32</td>\n",
       "      <td>Abdullah, Ameer</td>\n",
       "      <td>9.826278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>2</td>\n",
       "      <td>5800.0</td>\n",
       "      <td>97.92</td>\n",
       "      <td>Bridgewater, Teddy</td>\n",
       "      <td>17.613917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>2</td>\n",
       "      <td>5800.0</td>\n",
       "      <td>81.94</td>\n",
       "      <td>Abdullah, Ameer</td>\n",
       "      <td>17.613917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>2</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>139.48</td>\n",
       "      <td>Cooper, Amari</td>\n",
       "      <td>15.153535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>2</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>116.14</td>\n",
       "      <td>Andrews, Mark</td>\n",
       "      <td>15.153535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165</th>\n",
       "      <td>16</td>\n",
       "      <td>7600.0</td>\n",
       "      <td>154.46</td>\n",
       "      <td>Abdullah, Ameer</td>\n",
       "      <td>20.251832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6106</th>\n",
       "      <td>16</td>\n",
       "      <td>7600.0</td>\n",
       "      <td>67.40</td>\n",
       "      <td>Abdullah, Ameer</td>\n",
       "      <td>22.432519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6150</th>\n",
       "      <td>16</td>\n",
       "      <td>7900.0</td>\n",
       "      <td>92.18</td>\n",
       "      <td>Abdullah, Ameer</td>\n",
       "      <td>21.634566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6117</th>\n",
       "      <td>16</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>131.70</td>\n",
       "      <td>Abdullah, Ameer</td>\n",
       "      <td>23.694538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6303</th>\n",
       "      <td>16</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>131.70</td>\n",
       "      <td>Abdullah, Ameer</td>\n",
       "      <td>22.355062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Week  DK salary  Oppt_pts_allowed_lw                Name       pred\n",
       "663      2     4400.0                88.32     Abdullah, Ameer   9.826278\n",
       "465      2     5800.0                97.92  Bridgewater, Teddy  17.613917\n",
       "450      2     5800.0                81.94     Abdullah, Ameer  17.613917\n",
       "609      2     6300.0               139.48       Cooper, Amari  15.153535\n",
       "788      2     6300.0               116.14       Andrews, Mark  15.153535\n",
       "...    ...        ...                  ...                 ...        ...\n",
       "6165    16     7600.0               154.46     Abdullah, Ameer  20.251832\n",
       "6106    16     7600.0                67.40     Abdullah, Ameer  22.432519\n",
       "6150    16     7900.0                92.18     Abdullah, Ameer  21.634566\n",
       "6117    16     8500.0               131.70     Abdullah, Ameer  23.694538\n",
       "6303    16     9000.0               131.70     Abdullah, Ameer  22.355062\n",
       "\n",
       "[135 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_df = inverted_df.sort_values(by=['Week', 'DK salary'])\n",
    "inverted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d2d937b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Abdullah, Ameer       95\n",
       "Brees, Drew            4\n",
       "Carr, Derek            4\n",
       "Allen, Keenan          3\n",
       "Bridgewater, Teddy     3\n",
       "Adams, Davante         3\n",
       "Brown, A.J.            3\n",
       "Cousins, Kirk          2\n",
       "Cooper, Amari          2\n",
       "Allen, Josh            2\n",
       "Conner, James          2\n",
       "Burrow, Joe            2\n",
       "Brady, Tom             2\n",
       "Cook, Dalvin           2\n",
       "Barkley, Saquon        1\n",
       "Chubb, Nick            1\n",
       "Andrews, Mark          1\n",
       "Anderson, Robby        1\n",
       "Brown, Marquise        1\n",
       "Beckham Jr., Odell     1\n",
       "Name: Name, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_df['Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5e20cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
