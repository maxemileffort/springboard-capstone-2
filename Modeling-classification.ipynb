{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "## From the end of EDA:\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "So the moral of the story currently is that we have at the minimum a couple of heuristics for choosing players:\n",
    "\n",
    "- Choose value players, ie players with moderate price tags but good matchups\n",
    "- Choose players based on Def they play\n",
    "- Avoid expensive players, since statistically they are unable to produce high scores consistently.\n",
    "\n",
    "With these guidelines, week 1 will be a total gamble, since we won't have any real data besides salaries. Week 2 will be the first time we can use any defensive data to help with our decision making."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal for this notebook:\n",
    "\n",
    "Based on the conclusions from the EDA, we want to see if we can find a model that confirms these ideas across seasons, and also has a high enough (cross-validated) accuracy to warrant trying to use this with real money."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "Sci-kit Learn says, according to https://scikit-learn.org/stable/tutorial/machine_learning_map/, that we should be using the linear SVC classifier, but for the sake of this exercise, we are going to try many different models to see what produces the best result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic\n",
    "\n",
    "Instead of projecting individual player points, the notebook is going to classify players based on their potentials to score in certain catgories.\n",
    "\n",
    "- A player in the 0 category will be likely to score 15 points or less (players that should be ignored).\n",
    "- A player with a 1 classification will be likely to score between 15 and 20 points.\n",
    "- A player with a 2 classification will be likely to score 20+ points.\n",
    "- A player with a 3 classification will be likely to score 30+ points.\n",
    "\n",
    "Obviously we want to get as many true 3s as possible, but getting 100% accuracy on that seems implausible. So our model should tend to maximize the top left value (correctly predict poor picks) and have errors that trend towards the bottom right (bottom right 2x2) of the confusion matrix. The model should also minimize the rest of the values on the top row, and the left column.\n",
    "\n",
    "So the criteria for deciding on what model to proceed with is (in order of importance):\n",
    "1. Correct 3 predictions\n",
    "2. Correct 0 predictions\n",
    "3. Bottom right 2x2 has most counts\n",
    "4. Minimize top row \n",
    "5. Minimize left column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jump to:\n",
    "\n",
    "- [Model Testing](#test_run)\n",
    "- [Lineup Builder](#lineup_builder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# !conda install --yes --prefix {sys.prefix} -c conda-forge scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None # turn off some warnings\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need version 0.24.2 of sci-kit learn for this notebook to work\n",
    "# import sklearn\n",
    "# print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weekly_data(week, year):\n",
    "    \"\"\" get player data for designated week \"\"\"\n",
    "    file_path = f\"./csv's/{year}/year-{year}-week-{week}-DK-player_data.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "def get_ytd_season_data(year, current_week):\n",
    "    \"\"\" get data for current season up to most recent week \"\"\"\n",
    "    df = get_weekly_data(1,year)\n",
    "    for week in range(2,current_week+1):\n",
    "        try:\n",
    "            df = df.append(get_weekly_data(week, year), ignore_index=True)\n",
    "        except:\n",
    "            print(\"No data for week: \"+str(week))\n",
    "    df = df.drop(['Unnamed: 0', 'Year'], axis=1)\n",
    "    return df\n",
    "\n",
    "def get_season_data(year):\n",
    "    \"\"\" get entire season of data \"\"\"\n",
    "    df = get_weekly_data(1,year)\n",
    "    for week in range(2,17):\n",
    "        try:\n",
    "            df = df.append(get_weekly_data(week, year), ignore_index=True)\n",
    "        except:\n",
    "            print(\"No data for week: \"+str(week))\n",
    "    df = df.drop(['Unnamed: 0', 'Year'], axis=1)\n",
    "    return df\n",
    "\n",
    "def make_confusion_matrix(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "    return cm, acc_score\n",
    "\n",
    "def scale_features(sc_salary, sc_points, sc_pts_ald, X_train, X_test, first_time=False):\n",
    "    \"\"\" scales data for training \"\"\"\n",
    "    if first_time:\n",
    "        X_train['DK salary'] = sc_salary.fit_transform(X_train['DK salary'].values.reshape(-1,1))\n",
    "        X_train['DK points'] = sc_points.fit_transform(X_train['DK points'].values.reshape(-1,1))\n",
    "        X_train['Oppt_pts_allowed_lw'] = sc_pts_ald.fit_transform(X_train['Oppt_pts_allowed_lw'].values.reshape(-1,1))\n",
    "    X_test['DK salary'] = sc_salary.transform(X_test['DK salary'].values.reshape(-1,1))\n",
    "    X_test['DK points'] = sc_points.transform(X_test['DK points'].values.reshape(-1,1))\n",
    "    X_test['Oppt_pts_allowed_lw'] = sc_pts_ald.transform(X_test['Oppt_pts_allowed_lw'].values.reshape(-1,1))\n",
    "    return X_train, X_test\n",
    "\n",
    "def unscale_features(sc_salary, sc_points, sc_pts_ald, X_train, X_test):\n",
    "    \"\"\" used to change features back so that human readable information can be used to assess\n",
    "    lineups and player information and performance\"\"\"\n",
    "    X_train['DK salary'] = sc_salary.inverse_transform(X_train['DK salary'].values.reshape(-1,1))\n",
    "    X_train['DK points'] = sc_points.inverse_transform(X_train['DK points'].values.reshape(-1,1))\n",
    "    X_train['Oppt_pts_allowed_lw'] = sc_pts_ald.inverse_transform(X_train['Oppt_pts_allowed_lw'].values.reshape(-1,1))\n",
    "    X_test['DK salary'] = sc_salary.inverse_transform(X_test['DK salary'].values.reshape(-1,1))\n",
    "    X_test['avg_points'] = sc_points.inverse_transform(X_test['avg_points'].values.reshape(-1,1))\n",
    "    X_test['Oppt_pts_allowed_lw'] = sc_pts_ald.inverse_transform(X_test['Oppt_pts_allowed_lw'].values.reshape(-1,1))\n",
    "    return X_train, X_test\n",
    "\n",
    "def find_15_ptrs(df):\n",
    "    df['scoring_potential'] = 0\n",
    "    df['scoring_potential'] = np.where(df['DK points'] >= 10.0, 1, df['scoring_potential'])\n",
    "    return df\n",
    "\n",
    "def find_20_ptrs(df):\n",
    "    df['scoring_potential'] = np.where(df['DK points'] >= 20.0, 2, df['scoring_potential'])\n",
    "    return df\n",
    "\n",
    "def find_30_ptrs(df):\n",
    "    df['scoring_potential'] = np.where(df['DK points'] >= 30.0, 3, df['scoring_potential'])\n",
    "    return df\n",
    "\n",
    "def find_scoring_potentials(df):\n",
    "    \"\"\" classifies players as low, med, or high potentials for scoring points \"\"\"\n",
    "    df = find_15_ptrs(df)\n",
    "    df = find_20_ptrs(df)\n",
    "    df = find_30_ptrs(df)\n",
    "    return df\n",
    "\n",
    "def handle_nulls(df):\n",
    "    \"\"\" players that have nulls for any of the columns are \n",
    "    extremely likely to be under performing or going into a bye.\n",
    "    the one caveat is that some are possibly coming off a bye.\n",
    "    to handle this later, probably will drop them, save those\n",
    "    as a variable, and then re-merge after getting rid of the other\n",
    "    null values. \"\"\"\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "season = 2019\n",
    "dataset = get_season_data(season)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>Name</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Team</th>\n",
       "      <th>h/a</th>\n",
       "      <th>Oppt</th>\n",
       "      <th>DK points</th>\n",
       "      <th>DK salary</th>\n",
       "      <th>scoring_potential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Jackson, Lamar</td>\n",
       "      <td>QB</td>\n",
       "      <td>bal</td>\n",
       "      <td>a</td>\n",
       "      <td>mia</td>\n",
       "      <td>36.56</td>\n",
       "      <td>6000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Prescott, Dak</td>\n",
       "      <td>QB</td>\n",
       "      <td>dal</td>\n",
       "      <td>h</td>\n",
       "      <td>nyg</td>\n",
       "      <td>36.40</td>\n",
       "      <td>5900</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Watson, Deshaun</td>\n",
       "      <td>QB</td>\n",
       "      <td>hou</td>\n",
       "      <td>a</td>\n",
       "      <td>nor</td>\n",
       "      <td>31.72</td>\n",
       "      <td>6800</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Stafford, Matthew</td>\n",
       "      <td>QB</td>\n",
       "      <td>det</td>\n",
       "      <td>a</td>\n",
       "      <td>ari</td>\n",
       "      <td>31.60</td>\n",
       "      <td>5400</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Mahomes II, Patrick</td>\n",
       "      <td>QB</td>\n",
       "      <td>kan</td>\n",
       "      <td>a</td>\n",
       "      <td>jac</td>\n",
       "      <td>30.32</td>\n",
       "      <td>7200</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6398</th>\n",
       "      <td>16</td>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>Def</td>\n",
       "      <td>cin</td>\n",
       "      <td>a</td>\n",
       "      <td>mia</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6399</th>\n",
       "      <td>16</td>\n",
       "      <td>Carolina</td>\n",
       "      <td>Def</td>\n",
       "      <td>car</td>\n",
       "      <td>a</td>\n",
       "      <td>ind</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>16</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Def</td>\n",
       "      <td>was</td>\n",
       "      <td>h</td>\n",
       "      <td>nyg</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6401</th>\n",
       "      <td>16</td>\n",
       "      <td>New York G</td>\n",
       "      <td>Def</td>\n",
       "      <td>nyg</td>\n",
       "      <td>a</td>\n",
       "      <td>was</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6402</th>\n",
       "      <td>16</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Def</td>\n",
       "      <td>ten</td>\n",
       "      <td>h</td>\n",
       "      <td>nor</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6403 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Week                 Name  Pos Team h/a Oppt  DK points  DK salary  \\\n",
       "0        1       Jackson, Lamar   QB  bal   a  mia      36.56       6000   \n",
       "1        1        Prescott, Dak   QB  dal   h  nyg      36.40       5900   \n",
       "2        1      Watson, Deshaun   QB  hou   a  nor      31.72       6800   \n",
       "3        1    Stafford, Matthew   QB  det   a  ari      31.60       5400   \n",
       "4        1  Mahomes II, Patrick   QB  kan   a  jac      30.32       7200   \n",
       "...    ...                  ...  ...  ...  ..  ...        ...        ...   \n",
       "6398    16           Cincinnati  Def  cin   a  mia       0.00       2900   \n",
       "6399    16             Carolina  Def  car   a  ind      -1.00       2400   \n",
       "6400    16           Washington  Def  was   h  nyg      -1.00       2800   \n",
       "6401    16           New York G  Def  nyg   a  was      -1.00       2800   \n",
       "6402    16            Tennessee  Def  ten   h  nor      -1.00       2100   \n",
       "\n",
       "      scoring_potential  \n",
       "0                     3  \n",
       "1                     3  \n",
       "2                     3  \n",
       "3                     3  \n",
       "4                     3  \n",
       "...                 ...  \n",
       "6398                  0  \n",
       "6399                  0  \n",
       "6400                  0  \n",
       "6401                  0  \n",
       "6402                  0  \n",
       "\n",
       "[6403 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = handle_nulls(dataset)\n",
    "df = find_scoring_potentials(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>Name</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Team</th>\n",
       "      <th>h/a</th>\n",
       "      <th>Oppt</th>\n",
       "      <th>DK points</th>\n",
       "      <th>DK salary</th>\n",
       "      <th>scoring_potential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Def</td>\n",
       "      <td>sfo</td>\n",
       "      <td>a</td>\n",
       "      <td>tam</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Def</td>\n",
       "      <td>ten</td>\n",
       "      <td>a</td>\n",
       "      <td>cle</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2600</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1</td>\n",
       "      <td>New York J</td>\n",
       "      <td>Def</td>\n",
       "      <td>nyj</td>\n",
       "      <td>h</td>\n",
       "      <td>buf</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Def</td>\n",
       "      <td>min</td>\n",
       "      <td>h</td>\n",
       "      <td>atl</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>1</td>\n",
       "      <td>Green Bay</td>\n",
       "      <td>Def</td>\n",
       "      <td>gnb</td>\n",
       "      <td>a</td>\n",
       "      <td>chi</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6398</th>\n",
       "      <td>16</td>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>Def</td>\n",
       "      <td>cin</td>\n",
       "      <td>a</td>\n",
       "      <td>mia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6399</th>\n",
       "      <td>16</td>\n",
       "      <td>Carolina</td>\n",
       "      <td>Def</td>\n",
       "      <td>car</td>\n",
       "      <td>a</td>\n",
       "      <td>ind</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>16</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Def</td>\n",
       "      <td>was</td>\n",
       "      <td>h</td>\n",
       "      <td>nyg</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6401</th>\n",
       "      <td>16</td>\n",
       "      <td>New York G</td>\n",
       "      <td>Def</td>\n",
       "      <td>nyg</td>\n",
       "      <td>a</td>\n",
       "      <td>was</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6402</th>\n",
       "      <td>16</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Def</td>\n",
       "      <td>ten</td>\n",
       "      <td>h</td>\n",
       "      <td>nor</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Week           Name  Pos Team h/a Oppt  DK points  DK salary  \\\n",
       "414      1  San Francisco  Def  sfo   a  tam       27.0       2200   \n",
       "415      1      Tennessee  Def  ten   a  cle       23.0       2600   \n",
       "416      1     New York J  Def  nyj   h  buf       18.0       3100   \n",
       "417      1      Minnesota  Def  min   h  atl       16.0       3300   \n",
       "418      1      Green Bay  Def  gnb   a  chi       14.0       2700   \n",
       "...    ...            ...  ...  ...  ..  ...        ...        ...   \n",
       "6398    16     Cincinnati  Def  cin   a  mia        0.0       2900   \n",
       "6399    16       Carolina  Def  car   a  ind       -1.0       2400   \n",
       "6400    16     Washington  Def  was   h  nyg       -1.0       2800   \n",
       "6401    16     New York G  Def  nyg   a  was       -1.0       2800   \n",
       "6402    16      Tennessee  Def  ten   h  nor       -1.0       2100   \n",
       "\n",
       "      scoring_potential  \n",
       "414                   2  \n",
       "415                   2  \n",
       "416                   1  \n",
       "417                   1  \n",
       "418                   1  \n",
       "...                 ...  \n",
       "6398                  0  \n",
       "6399                  0  \n",
       "6400                  0  \n",
       "6401                  0  \n",
       "6402                  0  \n",
       "\n",
       "[480 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_df = df.loc[df.Pos == 'Def']\n",
    "def_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate defenses and assess how many fantasy \n",
    "# points they allowed last week. Then add that \n",
    "# as a feature to the training data. The idea is\n",
    "# the defenses that consistently allow the most points\n",
    "# will also product the highest scoring players\n",
    "\n",
    "def_df['fantasy_points_allowed_lw'] = 0\n",
    "df['Oppt_pts_allowed_lw'] = 0\n",
    "def_teams = [x for x in def_df['Team'].unique()]\n",
    "\n",
    "for week in range(1,17):\n",
    "    for team in def_teams:\n",
    "        try:\n",
    "            offense_df1 = df.loc[(df['Oppt']==team)&(df['Week']==week)]\n",
    "            offense_df2 = df.loc[(df['Oppt']==team)&(df['Week']==week+1)]\n",
    "            sum_ = offense_df1['DK points'].sum()\n",
    "            def_df.loc[(df['Team']==team)&(df['Week']==week+1), 'fantasy_points_allowed_lw'] = sum_\n",
    "            df.loc[(df['Oppt']==team)&(df['Week']==week+1), 'Oppt_pts_allowed_lw'] = sum_\n",
    "        except:\n",
    "            print('couldnt append data')\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>Name</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Team</th>\n",
       "      <th>h/a</th>\n",
       "      <th>Oppt</th>\n",
       "      <th>DK points</th>\n",
       "      <th>DK salary</th>\n",
       "      <th>scoring_potential</th>\n",
       "      <th>fantasy_points_allowed_lw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>Def</td>\n",
       "      <td>sfo</td>\n",
       "      <td>a</td>\n",
       "      <td>tam</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Def</td>\n",
       "      <td>ten</td>\n",
       "      <td>a</td>\n",
       "      <td>cle</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2600</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1</td>\n",
       "      <td>New York J</td>\n",
       "      <td>Def</td>\n",
       "      <td>nyj</td>\n",
       "      <td>h</td>\n",
       "      <td>buf</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Def</td>\n",
       "      <td>min</td>\n",
       "      <td>h</td>\n",
       "      <td>atl</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>1</td>\n",
       "      <td>Green Bay</td>\n",
       "      <td>Def</td>\n",
       "      <td>gnb</td>\n",
       "      <td>a</td>\n",
       "      <td>chi</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2700</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6398</th>\n",
       "      <td>16</td>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>Def</td>\n",
       "      <td>cin</td>\n",
       "      <td>a</td>\n",
       "      <td>mia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2900</td>\n",
       "      <td>0</td>\n",
       "      <td>96.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6399</th>\n",
       "      <td>16</td>\n",
       "      <td>Carolina</td>\n",
       "      <td>Def</td>\n",
       "      <td>car</td>\n",
       "      <td>a</td>\n",
       "      <td>ind</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2400</td>\n",
       "      <td>0</td>\n",
       "      <td>119.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>16</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Def</td>\n",
       "      <td>was</td>\n",
       "      <td>h</td>\n",
       "      <td>nyg</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2800</td>\n",
       "      <td>0</td>\n",
       "      <td>128.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6401</th>\n",
       "      <td>16</td>\n",
       "      <td>New York G</td>\n",
       "      <td>Def</td>\n",
       "      <td>nyg</td>\n",
       "      <td>a</td>\n",
       "      <td>was</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2800</td>\n",
       "      <td>0</td>\n",
       "      <td>99.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6402</th>\n",
       "      <td>16</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Def</td>\n",
       "      <td>ten</td>\n",
       "      <td>h</td>\n",
       "      <td>nor</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2100</td>\n",
       "      <td>0</td>\n",
       "      <td>103.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Week           Name  Pos Team h/a Oppt  DK points  DK salary  \\\n",
       "414      1  San Francisco  Def  sfo   a  tam       27.0       2200   \n",
       "415      1      Tennessee  Def  ten   a  cle       23.0       2600   \n",
       "416      1     New York J  Def  nyj   h  buf       18.0       3100   \n",
       "417      1      Minnesota  Def  min   h  atl       16.0       3300   \n",
       "418      1      Green Bay  Def  gnb   a  chi       14.0       2700   \n",
       "...    ...            ...  ...  ...  ..  ...        ...        ...   \n",
       "6398    16     Cincinnati  Def  cin   a  mia        0.0       2900   \n",
       "6399    16       Carolina  Def  car   a  ind       -1.0       2400   \n",
       "6400    16     Washington  Def  was   h  nyg       -1.0       2800   \n",
       "6401    16     New York G  Def  nyg   a  was       -1.0       2800   \n",
       "6402    16      Tennessee  Def  ten   h  nor       -1.0       2100   \n",
       "\n",
       "      scoring_potential  fantasy_points_allowed_lw  \n",
       "414                   2                       0.00  \n",
       "415                   2                       0.00  \n",
       "416                   1                       0.00  \n",
       "417                   1                       0.00  \n",
       "418                   1                       0.00  \n",
       "...                 ...                        ...  \n",
       "6398                  0                      96.42  \n",
       "6399                  0                     119.44  \n",
       "6400                  0                     128.94  \n",
       "6401                  0                      99.26  \n",
       "6402                  0                     103.02  \n",
       "\n",
       "[480 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Week</th>\n",
       "      <th>Name</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Team</th>\n",
       "      <th>h/a</th>\n",
       "      <th>Oppt</th>\n",
       "      <th>DK points</th>\n",
       "      <th>DK salary</th>\n",
       "      <th>scoring_potential</th>\n",
       "      <th>Oppt_pts_allowed_lw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>2</td>\n",
       "      <td>Mahomes II, Patrick</td>\n",
       "      <td>QB</td>\n",
       "      <td>kan</td>\n",
       "      <td>a</td>\n",
       "      <td>oak</td>\n",
       "      <td>35.62</td>\n",
       "      <td>7500</td>\n",
       "      <td>3</td>\n",
       "      <td>81.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>2</td>\n",
       "      <td>Jackson, Lamar</td>\n",
       "      <td>QB</td>\n",
       "      <td>bal</td>\n",
       "      <td>h</td>\n",
       "      <td>ari</td>\n",
       "      <td>33.88</td>\n",
       "      <td>6700</td>\n",
       "      <td>3</td>\n",
       "      <td>137.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>2</td>\n",
       "      <td>Prescott, Dak</td>\n",
       "      <td>QB</td>\n",
       "      <td>dal</td>\n",
       "      <td>a</td>\n",
       "      <td>was</td>\n",
       "      <td>28.66</td>\n",
       "      <td>6300</td>\n",
       "      <td>2</td>\n",
       "      <td>129.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>2</td>\n",
       "      <td>Wilson, Russell</td>\n",
       "      <td>QB</td>\n",
       "      <td>sea</td>\n",
       "      <td>a</td>\n",
       "      <td>pit</td>\n",
       "      <td>28.20</td>\n",
       "      <td>6200</td>\n",
       "      <td>2</td>\n",
       "      <td>130.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>2</td>\n",
       "      <td>Ryan, Matt</td>\n",
       "      <td>QB</td>\n",
       "      <td>atl</td>\n",
       "      <td>h</td>\n",
       "      <td>phi</td>\n",
       "      <td>25.10</td>\n",
       "      <td>6100</td>\n",
       "      <td>2</td>\n",
       "      <td>122.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6398</th>\n",
       "      <td>16</td>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>Def</td>\n",
       "      <td>cin</td>\n",
       "      <td>a</td>\n",
       "      <td>mia</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2900</td>\n",
       "      <td>0</td>\n",
       "      <td>123.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6399</th>\n",
       "      <td>16</td>\n",
       "      <td>Carolina</td>\n",
       "      <td>Def</td>\n",
       "      <td>car</td>\n",
       "      <td>a</td>\n",
       "      <td>ind</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2400</td>\n",
       "      <td>0</td>\n",
       "      <td>134.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>16</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Def</td>\n",
       "      <td>was</td>\n",
       "      <td>h</td>\n",
       "      <td>nyg</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2800</td>\n",
       "      <td>0</td>\n",
       "      <td>99.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6401</th>\n",
       "      <td>16</td>\n",
       "      <td>New York G</td>\n",
       "      <td>Def</td>\n",
       "      <td>nyg</td>\n",
       "      <td>a</td>\n",
       "      <td>was</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2800</td>\n",
       "      <td>0</td>\n",
       "      <td>128.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6402</th>\n",
       "      <td>16</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Def</td>\n",
       "      <td>ten</td>\n",
       "      <td>h</td>\n",
       "      <td>nor</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2100</td>\n",
       "      <td>0</td>\n",
       "      <td>50.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5957 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Week                 Name  Pos Team h/a Oppt  DK points  DK salary  \\\n",
       "446      2  Mahomes II, Patrick   QB  kan   a  oak      35.62       7500   \n",
       "447      2       Jackson, Lamar   QB  bal   h  ari      33.88       6700   \n",
       "448      2        Prescott, Dak   QB  dal   a  was      28.66       6300   \n",
       "449      2      Wilson, Russell   QB  sea   a  pit      28.20       6200   \n",
       "450      2           Ryan, Matt   QB  atl   h  phi      25.10       6100   \n",
       "...    ...                  ...  ...  ...  ..  ...        ...        ...   \n",
       "6398    16           Cincinnati  Def  cin   a  mia       0.00       2900   \n",
       "6399    16             Carolina  Def  car   a  ind      -1.00       2400   \n",
       "6400    16           Washington  Def  was   h  nyg      -1.00       2800   \n",
       "6401    16           New York G  Def  nyg   a  was      -1.00       2800   \n",
       "6402    16            Tennessee  Def  ten   h  nor      -1.00       2100   \n",
       "\n",
       "      scoring_potential  Oppt_pts_allowed_lw  \n",
       "446                   3                81.02  \n",
       "447                   3               137.50  \n",
       "448                   2               129.12  \n",
       "449                   2               130.12  \n",
       "450                   2               122.00  \n",
       "...                 ...                  ...  \n",
       "6398                  0               123.56  \n",
       "6399                  0               134.68  \n",
       "6400                  0                99.26  \n",
       "6401                  0               128.94  \n",
       "6402                  0                50.70  \n",
       "\n",
       "[5957 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df.Week != 1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(labels='scoring_potential', axis=1)\n",
    "y = df['scoring_potential']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal encode names, teams, h/a and oppts\n",
    "oe_names = OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value = -1)\n",
    "oe_teams = OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value = -1)\n",
    "oe_ha = OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value = -1)\n",
    "oe_oppts = OrdinalEncoder(handle_unknown = 'use_encoded_value', unknown_value = -1)\n",
    "\n",
    "def ft_ordinal_encode_df(df, oe_names, oe_teams, oe_ha, oe_oppts):\n",
    "    df['Name'] = oe_names.fit_transform(df['Name'].values.reshape(-1,1))\n",
    "    df['Team'] = oe_teams.fit_transform(df['Team'].values.reshape(-1,1))\n",
    "    df['Oppt'] = oe_oppts.fit_transform(df['Oppt'].values.reshape(-1,1))\n",
    "    df['h/a'] = oe_ha.fit_transform(df['h/a'].values.reshape(-1,1))\n",
    "    return df\n",
    "\n",
    "def t_ordinal_encode_df(df, oe_names, oe_teams, oe_ha, oe_oppts):\n",
    "    df['Name'] = oe_names.transform(df['Name'].values.reshape(-1,1))\n",
    "    df['Team'] = oe_teams.transform(df['Team'].values.reshape(-1,1))\n",
    "    df['Oppt'] = oe_oppts.transform(df['Oppt'].values.reshape(-1,1))\n",
    "    df['h/a'] = oe_ha.transform(df['h/a'].values.reshape(-1,1))\n",
    "    return df\n",
    "\n",
    "def it_ordinal_encode_df(df, oe_names, oe_teams, oe_ha, oe_oppts):\n",
    "    df['Name'] = oe_names.inverse_transform(df['Name'].values.reshape(-1,1))\n",
    "    df['Team'] = oe_teams.inverse_transform(df['Team'].values.reshape(-1,1))\n",
    "    df['Oppt'] = oe_oppts.inverse_transform(df['Oppt'].values.reshape(-1,1))\n",
    "    df['h/a'] = oe_ha.inverse_transform(df['h/a'].values.reshape(-1,1))\n",
    "    return df\n",
    "\n",
    "X = ft_ordinal_encode_df(X, oe_names, oe_teams, oe_ha, oe_oppts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the positions\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "xtr_cols = X_train.columns\n",
    "xte_cols = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_use = 'scaled'\n",
    "# data_to_use = 'un-scaled' # comment out this line for using scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_to_use == 'scaled':\n",
    "#     sc_salary = StandardScaler()\n",
    "#     sc_points = StandardScaler()\n",
    "#     sc_pts_ald = StandardScaler()\n",
    "    sc_salary = MinMaxScaler()\n",
    "    sc_points = MinMaxScaler()\n",
    "    sc_pts_ald = MinMaxScaler()\n",
    "    X_train, X_test = scale_features(sc_salary, sc_points, sc_pts_ald, X_train, X_test, first_time=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Boost Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test some models to see which have the best performance overall based on an entire previous season of data. Based on that, use a model or 2 to predict outcomes on a different season, where we will use a partial season of data to predict the next week in sequence, much like would happen in a live situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "\n",
      "[[836   0   0   2]\n",
      " [236   3   0   0]\n",
      " [ 83   4   0   0]\n",
      " [ 27   1   0   0]]\n",
      "\n",
      "\n",
      "Accuracy: \n",
      "\n",
      "0.7038590604026845\n",
      "\n",
      "\n",
      "F1: \n",
      "\n",
      "0.5867763013292878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxw2\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "best_acc_method = \"\"\n",
    "best_f1_method = \"\"\n",
    "best_acc = -100\n",
    "best_f1 = -100\n",
    "\n",
    "# Logistic Regression\n",
    "def make_log_reg(X_train, y_train, X_test, y_test):\n",
    "    classifier = LogisticRegression(random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    cm, acc_score = make_confusion_matrix(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Confusion Matrix: \\n\")\n",
    "    print(cm)\n",
    "    print(\"\\n\")\n",
    "    print(\"Accuracy: \\n\")\n",
    "    print(acc_score)\n",
    "    print(\"\\n\")\n",
    "    print(\"F1: \\n\")\n",
    "    print(f1)\n",
    "    return cm, acc_score, f1\n",
    "\n",
    "lr_acc = 0\n",
    "try:\n",
    "    cm, acc_score, f1 = make_log_reg(X_train, y_train,X_test,y_test)\n",
    "    lr_acc = acc_score\n",
    "    if acc_score > best_acc:\n",
    "        best_acc = acc_score\n",
    "        best_acc_method = \"Logistic Regression\"\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_f1_method = \"Logistic Regression\"\n",
    "except ValueError:\n",
    "    # sample sizes are mismatched\n",
    "    print(\"ValueError\")\n",
    "except IndexError:\n",
    "    # end of the loop\n",
    "    print(\"IndexError\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "\n",
      "[[735  88  13   2]\n",
      " [190  40   8   1]\n",
      " [ 59  22   2   4]\n",
      " [ 20   6   2   0]]\n",
      "\n",
      "\n",
      "Accuracy: \n",
      "\n",
      "0.6518456375838926\n",
      "\n",
      "\n",
      "F1: \n",
      "\n",
      "0.60425706470805\n"
     ]
    }
   ],
   "source": [
    "# K-NN \n",
    "def make_knn(X_train, y_train, X_test, y_test):\n",
    "    classifier = KNeighborsClassifier(n_neighbors = 3, metric = 'minkowski', p = 2)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    cm, acc_score = make_confusion_matrix(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Confusion Matrix: \\n\")\n",
    "    print(cm)\n",
    "    print(\"\\n\")\n",
    "    print(\"Accuracy: \\n\")\n",
    "    print(acc_score)\n",
    "    print(\"\\n\")\n",
    "    print(\"F1: \\n\")\n",
    "    print(f1)\n",
    "    return cm, acc_score, f1\n",
    "\n",
    "knn_acc = 0\n",
    "try:\n",
    "    cm, acc_score, f1 = make_knn(X_train, y_train,X_test,y_test)\n",
    "    knn_acc = acc_score\n",
    "    if acc_score > best_acc:\n",
    "        best_acc = acc_score\n",
    "        best_acc_method = \"K-NN\"\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_f1_method = \"K-NN\"\n",
    "except ValueError:\n",
    "    # sample sizes are mismatched\n",
    "    print(\"ValueError\")\n",
    "except IndexError:\n",
    "    # end of the loop\n",
    "    print(\"IndexError\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM \n",
    "def make_svm(X_train, y_train, X_test, y_test):\n",
    "    classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    cm, acc_score = make_confusion_matrix(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Confusion Matrix: \\n\")\n",
    "    print(cm)\n",
    "    print(\"\\n\")\n",
    "    print(\"Accuracy: \\n\")\n",
    "    print(acc_score)\n",
    "    print(\"\\n\")\n",
    "    print(\"F1: \\n\")\n",
    "    print(f1)\n",
    "    return cm, acc_score, f1\n",
    "\n",
    "svm_acc = 0\n",
    "try:\n",
    "    cm, acc_score, f1 = make_svm(X_train, y_train,X_test,y_test)\n",
    "    svm_acc = acc_score\n",
    "    if acc_score > best_acc:\n",
    "        best_acc = acc_score\n",
    "        best_acc_method = \"SVM\"\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_f1_method = \"SVM\"\n",
    "except ValueError:\n",
    "    # sample sizes are mismatched\n",
    "    print(\"ValueError\")\n",
    "except IndexError:\n",
    "    # end of the loop\n",
    "    print(\"IndexError\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel SVM\n",
    "\n",
    "def make_k_svm(X_train, y_train, X_test, y_test):\n",
    "    classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    cm, acc_score = make_confusion_matrix(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Confusion Matrix: \\n\")\n",
    "    print(cm)\n",
    "    print(\"\\n\")\n",
    "    print(\"Accuracy: \\n\")\n",
    "    print(acc_score)\n",
    "    print(\"\\n\")\n",
    "    print(\"F1: \\n\")\n",
    "    print(f1)\n",
    "    return cm, acc_score, f1\n",
    "\n",
    "k_svm_acc = 0\n",
    "try:\n",
    "    cm, acc_score, f1 = make_k_svm(X_train, y_train,X_test,y_test)\n",
    "    k_svm_acc = acc_score\n",
    "    if acc_score > best_acc:\n",
    "        best_acc = acc_score\n",
    "        best_acc_method = \"Kernel SVM\"\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_f1_method = \"Kernel SVM\"\n",
    "except ValueError:\n",
    "    # sample sizes are mismatched\n",
    "    print(\"ValueError\")\n",
    "except IndexError:\n",
    "    # end of the loop\n",
    "    print(\"IndexError\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "def make_nb(X_train, y_train, X_test, y_test):\n",
    "    classifier = GaussianNB()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    cm, acc_score = make_confusion_matrix(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Confusion Matrix: \\n\")\n",
    "    print(cm)\n",
    "    print(\"\\n\")\n",
    "    print(\"Accuracy: \\n\")\n",
    "    print(acc_score)\n",
    "    print(\"\\n\")\n",
    "    print(\"F1: \\n\")\n",
    "    print(f1)\n",
    "    return cm, acc_score, f1\n",
    "\n",
    "nb_acc = 0\n",
    "try:\n",
    "    cm, acc_score, f1 = make_nb(X_train, y_train,X_test,y_test)\n",
    "    nb_acc = acc_score\n",
    "    if acc_score > best_acc:\n",
    "        best_acc = acc_score\n",
    "        best_acc_method = \"Naive Bayes\"\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_f1_method = \"Naive Bayes\"\n",
    "except ValueError:\n",
    "    # sample sizes are mismatched\n",
    "    print(\"ValueError\")\n",
    "except IndexError:\n",
    "    # end of the loop\n",
    "    print(\"IndexError\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree \n",
    "def make_tree(X_train, y_train, X_test, y_test):\n",
    "    classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    cm, acc_score = make_confusion_matrix(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Confusion Matrix: \\n\")\n",
    "    print(cm)\n",
    "    print(\"\\n\")\n",
    "    print(\"Accuracy: \\n\")\n",
    "    print(acc_score)\n",
    "    print(\"\\n\")\n",
    "    print(\"F1: \\n\")\n",
    "    print(f1)\n",
    "    return cm, acc_score, f1\n",
    "\n",
    "dt_acc = 0\n",
    "try:\n",
    "    cm, acc_score, f1 = make_tree(X_train, y_train,X_test,y_test)\n",
    "    dt_acc = acc_score\n",
    "    if acc_score > best_acc:\n",
    "        best_acc = acc_score\n",
    "        best_acc_method = \"Decision Tree\"\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_f1_method = \"Decision Tree\"\n",
    "except ValueError:\n",
    "    # sample sizes are mismatched\n",
    "    print(\"ValueError\")\n",
    "    pass\n",
    "except IndexError:\n",
    "    # end of the loop\n",
    "    print(\"IndexError\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "def make_forest(X_train, y_train, X_test, y_test):\n",
    "    classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    cm, acc_score = make_confusion_matrix(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Confusion Matrix: \\n\")\n",
    "    print(cm)\n",
    "    print(\"\\n\")\n",
    "    print(\"Accuracy: \\n\")\n",
    "    print(acc_score)\n",
    "    print(\"\\n\")\n",
    "    print(\"F1: \\n\")\n",
    "    print(f1)\n",
    "    return cm, acc_score, f1\n",
    "\n",
    "rf_acc = 0\n",
    "try:\n",
    "    cm, acc_score, f1 = make_forest(X_train, y_train,X_test,y_test)\n",
    "    rf_acc = acc_score\n",
    "    if acc_score > best_acc:\n",
    "        best_acc = acc_score\n",
    "        best_acc_method = \"Random Forest\"\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_f1_method = \"Random Forest\"\n",
    "except ValueError:\n",
    "    # sample sizes are mismatched\n",
    "    print(\"ValueError\")\n",
    "except IndexError:\n",
    "    # end of the loop\n",
    "    print(\"IndexError\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(best_acc)\n",
    "print(best_acc_method)\n",
    "print(best_f1)\n",
    "print(best_f1_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boost Methods (using non-scaled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc_method = \"\"\n",
    "best_f1_method = \"\"\n",
    "best_acc = -100\n",
    "best_f1 = -100\n",
    "\n",
    "# AdaBoost\n",
    "def make_adaboost(X_train, y_train, X_test, y_test):\n",
    "    classifier = AdaBoostClassifier()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    cm, acc_score = make_confusion_matrix(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Confusion Matrix: \\n\")\n",
    "    print(cm)\n",
    "    print(\"\\n\")\n",
    "    print(\"Accuracy: \\n\")\n",
    "    print(acc_score)\n",
    "    print(\"\\n\")\n",
    "    print(\"F1: \\n\")\n",
    "    print(f1)\n",
    "    return cm, acc_score, f1\n",
    "\n",
    "ada_acc = 0\n",
    "try:\n",
    "    cm, acc_score, f1 = make_adaboost(X_train, y_train,X_test,y_test)\n",
    "    ada_acc = acc_score\n",
    "    if acc_score > best_acc:\n",
    "        best_acc = acc_score\n",
    "        best_acc_method = \"AdaBoost\"\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_f1_method = \"AdaBoost\"\n",
    "except ValueError:\n",
    "    # sample sizes are mismatched\n",
    "    print(\"ValueError\")\n",
    "except IndexError:\n",
    "    # end of the loop\n",
    "    print(\"IndexError\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoost\n",
    "def make_gradientboost(X_train, y_train, X_test, y_test):\n",
    "    classifier = GradientBoostingClassifier()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    cm, acc_score = make_confusion_matrix(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Confusion Matrix: \\n\")\n",
    "    print(cm)\n",
    "    print(\"\\n\")\n",
    "    print(\"Accuracy: \\n\")\n",
    "    print(acc_score)\n",
    "    print(\"\\n\")\n",
    "    print(\"F1: \\n\")\n",
    "    print(f1)\n",
    "    return cm, acc_score, f1\n",
    "\n",
    "grad_acc = 0\n",
    "try:\n",
    "    cm, acc_score, f1 = make_gradientboost(X_train, y_train,X_test,y_test)\n",
    "    grad_acc = acc_score\n",
    "    if acc_score > best_acc:\n",
    "        best_acc = acc_score\n",
    "        best_acc_method = \"Gradient Boost\"\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_f1_method = \"Gradient Boost\"\n",
    "except ValueError:\n",
    "    # sample sizes are mismatched\n",
    "    print(\"ValueError\")\n",
    "except IndexError:\n",
    "    # end of the loop\n",
    "    print(\"IndexError\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "def make_xgboost(X_train, y_train, X_test, y_test):\n",
    "    classifier = XGBClassifier()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    cm, acc_score = make_confusion_matrix(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(\"Confusion Matrix: \\n\")\n",
    "    print(cm)\n",
    "    print(\"\\n\")\n",
    "    print(\"Accuracy: \\n\")\n",
    "    print(acc_score)\n",
    "    print(\"\\n\")\n",
    "    print(\"F1: \\n\")\n",
    "    print(f1)\n",
    "    return cm, acc_score, f1\n",
    "\n",
    "xg_acc = 0\n",
    "try:\n",
    "    cm, acc_score, f1 = make_xgboost(X_train, y_train,X_test,y_test)\n",
    "    xg_acc = acc_score\n",
    "    if acc_score > best_acc:\n",
    "        best_acc = acc_score\n",
    "        best_acc_method = \"XGBoost\"\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_f1_method = \"XGBoost\"\n",
    "except ValueError:\n",
    "    # sample sizes are mismatched\n",
    "    print(\"ValueError\")\n",
    "except IndexError:\n",
    "    # end of the loop\n",
    "    print(\"IndexError\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(best_acc)\n",
    "print(best_acc_method)\n",
    "print(best_f1)\n",
    "print(best_f1_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LR: \" + str(lr_acc))\n",
    "print(\"KNN: \" + str(knn_acc))\n",
    "print(\"SVM: \" + str(svm_acc))\n",
    "print(\"K_SVM: \" + str(k_svm_acc))\n",
    "print(\"NB: \" + str(nb_acc))\n",
    "print(\"DT: \" + str(dt_acc))\n",
    "print(\"RF: \" + str(rf_acc))\n",
    "print(\"Ada: \" + str(ada_acc))\n",
    "print(\"Grad: \" + str(grad_acc))\n",
    "print(\"XGB: \" + str(xg_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From just the baselines, all of the models have super high mean accuracies, which is promising, but I remain skeptical. SVM, Naive Bayes, and Decision Trees are at the top for non-boosted methods, while Gradient and XGBoosting are the best boosted methods.\n",
    "\n",
    "So next, we want to try a run where we use an example week of data, and try to project possible high scoring players for the following week.\n",
    "\n",
    "We'll use the best scoring methods mentioned above to see how they perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Run\n",
    "\n",
    "<a id='test_run'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's say that week 7 just finished, and week 8 is coming up.\n",
    "# time to put together a lineup for week 8, or at least form a pool\n",
    "# of suspected high scoring players.\n",
    "\n",
    "# mess with these numbers to experiment, but \n",
    "# comments below are for week 7 in the 2020 season\n",
    "\n",
    "season = 2020\n",
    "week = 7\n",
    "next_week = week+1 # will be used a little later\n",
    "\n",
    "if week == 1:\n",
    "    dataset = get_season_data(season-1)\n",
    "else: \n",
    "    dataset = get_ytd_season_data(season, week)\n",
    "    \n",
    "df_next_week = get_weekly_data(next_week, season).drop(labels=['Unnamed: 0', 'Year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_next_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ytd = find_scoring_potentials(dataset)\n",
    "df_ytd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def_df = df_ytd.loc[df_ytd.Pos == 'Def']\n",
    "def_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_df['fantasy_points_allowed_lw'] = 0\n",
    "df_ytd['Oppt_pts_allowed_lw'] = 0\n",
    "def_teams = [x for x in def_df['Team'].unique()]\n",
    "\n",
    "for week in range(1,week+1):\n",
    "    for team in def_teams:\n",
    "        try:\n",
    "            offense_df1 = df_ytd.loc[(df_ytd['Oppt']==team)&(df_ytd['Week']==week)]\n",
    "            offense_df2 = df_ytd.loc[(df_ytd['Oppt']==team)&(df_ytd['Week']==week+1)]\n",
    "            sum_ = offense_df1['DK points'].sum()\n",
    "            try:\n",
    "                def_df.loc[(df_ytd['Team']==team)&(df_ytd['Week']==week+1), 'fantasy_points_allowed_lw'] = sum_\n",
    "            except:\n",
    "                print(\"couldn't append first sum\")\n",
    "                pass\n",
    "            try:\n",
    "                df_ytd.loc[(df_ytd['Oppt']==team)&(df_ytd['Week']==week+1), 'Oppt_pts_allowed_lw'] = sum_\n",
    "            except:\n",
    "                print(\"couldn't append second sum\")\n",
    "                pass\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_next_week['Oppt_pts_allowed_lw'] = 0\n",
    "def_teams = [x for x in def_df['Team'].unique()]\n",
    "\n",
    "for team in def_teams:\n",
    "    try:\n",
    "        offense_df1 = df_ytd.loc[(df_ytd['Oppt']==team)&(df_ytd['Week']==week)]\n",
    "        sum_ = offense_df1['DK points'].sum()\n",
    "        \n",
    "        try:\n",
    "            df_next_week.loc[(df_next_week['Oppt']==team), 'Oppt_pts_allowed_lw'] = sum_\n",
    "        except:\n",
    "            print(\"couldn't append second sum\")\n",
    "            pass\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because we won't have access to some stats since we are trying to \n",
    "# project into the future, we'll need to be a little more creative.\n",
    "# Instead of dropping 'DK points', substitute avg PPG for that value\n",
    "\n",
    "def get_avg_ppg(ytd_df, player_name):\n",
    "    filt = ytd_df['Name']==player_name\n",
    "    working_df = ytd_df.loc[filt]\n",
    "    mean = np.mean(working_df['DK points'])\n",
    "    return mean\n",
    "\n",
    "# def get_avg_ppg(ytd_df, player_name):\n",
    "#     one_hot_columns = (ytd_df.iloc[:, 4:] == 1).idxmax(1)\n",
    "#     ytd_df['player_name'] = one_hot_columns\n",
    "#     ytd_df['player_name'] = ytd_df['player_name'].str.replace(\"Name_\", \"\")\n",
    "#     filt = ytd_df['player_name']==player_name\n",
    "#     working_df = ytd_df.loc[filt]\n",
    "#     mean = np.mean(working_df['DK points'])\n",
    "#     return mean\n",
    "\n",
    "# def get_avg_scoring_potential(ytd_df, player_name):\n",
    "#     filt = ytd_df['Name']==player_name\n",
    "#     working_df = ytd_df.loc[filt]\n",
    "#     mean = round(np.mean(working_df['scoring_potential']),0)\n",
    "#     return mean\n",
    "\n",
    "if week == 1:\n",
    "    df_next_week['DK points'] = 0\n",
    "    for num in range(0,len(df_next_week)):\n",
    "        df_next_week['DK points'][num] = get_avg_ppg(df_ytd, df_next_week['Name'][num])\n",
    "else:\n",
    "    df_next_week['DK points'] = 0\n",
    "#     df_next_week['scoring_potential'] = 0\n",
    "    for num in range(0,len(df_next_week)):\n",
    "        df_next_week['DK points'][num] = get_avg_ppg(df_ytd, df_next_week['Name'][num])\n",
    "#         df_next_week['scoring_potential'][num] = get_avg_scoring_potential(df_ytd, df_next_week['Name'][num])\n",
    "df_next_week = df_next_week.fillna(0)\n",
    "df_next_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal encode names, teams, h/a and oppts\n",
    "df_ytd = ft_ordinal_encode_df(df_ytd, oe_names, oe_teams, oe_ha, oe_oppts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies on the rest\n",
    "df_ytd = pd.get_dummies(df_ytd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ytd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_next_week = t_ordinal_encode_df(df_next_week, oe_names, oe_teams, oe_ha, oe_oppts)\n",
    "df_next_week = find_scoring_potentials(df_next_week)\n",
    "df_next_week = pd.get_dummies(df_next_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_next_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_ytd.drop(labels='scoring_potential', axis=1)\n",
    "y = df_ytd['scoring_potential']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data for models that need scaling\n",
    "scaled_X_train, scaled_X_test = scale_features(sc_salary, sc_points, sc_pts_ald, X_train, X_test, first_time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = SVC(kernel = 'linear', random_state = 0)\n",
    "nb_clf = GaussianNB()\n",
    "dt_clf = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "# grad_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1, max_depth=2, random_state=0)\n",
    "grad_clf = GradientBoostingClassifier()\n",
    "xgb_clf = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "svm_clf.fit(scaled_X_train, y_train)\n",
    "y_pred = svm_clf.predict(scaled_X_test)\n",
    "cm, acc_score = make_confusion_matrix(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"Confusion Matrix: \\n\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy: \\n\")\n",
    "print(acc_score)\n",
    "print(\"\\n\")\n",
    "print(\"F1: \\n\")\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "nb_clf.fit(scaled_X_train, y_train)\n",
    "y_pred = nb_clf.predict(scaled_X_test)\n",
    "cm, acc_score = make_confusion_matrix(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"Confusion Matrix: \\n\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy: \\n\")\n",
    "print(acc_score)\n",
    "print(\"\\n\")\n",
    "print(\"F1: \\n\")\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt_clf.fit(scaled_X_train, y_train)\n",
    "y_pred = dt_clf.predict(scaled_X_test)\n",
    "cm, acc_score = make_confusion_matrix(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"Confusion Matrix: \\n\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy: \\n\")\n",
    "print(acc_score)\n",
    "print(\"\\n\")\n",
    "print(\"F1: \\n\")\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boost\n",
    "grad_clf.fit(scaled_X_train, y_train)\n",
    "y_pred = grad_clf.predict(scaled_X_test)\n",
    "cm, acc_score = make_confusion_matrix(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"Confusion Matrix: \\n\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy: \\n\")\n",
    "print(acc_score)\n",
    "print(\"\\n\")\n",
    "print(\"F1: \\n\")\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgb_clf.fit(scaled_X_train, y_train)\n",
    "y_pred = xgb_clf.predict(scaled_X_test)\n",
    "cm, acc_score = make_confusion_matrix(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"Confusion Matrix: \\n\")\n",
    "print(cm)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy: \\n\")\n",
    "print(acc_score)\n",
    "print(\"\\n\")\n",
    "print(\"F1: \\n\")\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it's interesting here that with training the models the boosted methods and Decision trees continue to have perfect scores, which I am guessing means there's some overfitting going on. So I'd say those ones, we can safely ignore.\n",
    "\n",
    "That leaves us with just 2 of the non-boosted methods (SVM & Naive Bayes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_next_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_next_week.copy()\n",
    "x_train_dumy, X_test_scaled = scale_features(sc_salary, sc_points, sc_pts_ald,X_train,X_test)\n",
    "y_test_scaled = X_test_scaled['scoring_potential']\n",
    "X_test_scaled = X_test_scaled.drop(labels=\"scoring_potential\", axis=1)\n",
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use svm_clf \n",
    "y_pred = svm_clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check_results = get_weekly_data(next_week, season).drop(['Unnamed: 0', 'Year'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array(find_scoring_potentials(df_check_results)[['scoring_potential']]).flatten()\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm, acc_score = make_confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":Sad Face Emoji: Right away, the thing that stands out is that SVM predicts a LOT of 30 pt scorers, which wasn't reflected before.\n",
    "\n",
    "So now let's check the other models and see how they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nb = nb_clf.predict(X_test_scaled)\n",
    "y_pred_dt = dt_clf.predict(X_test_scaled)\n",
    "y_pred_grad = grad_clf.predict(X_test_scaled)\n",
    "y_pred_xgb = xgb_clf.predict(X_test_scaled)\n",
    "\n",
    "cm_nb, acc_score_nb = make_confusion_matrix(y_true, y_pred_nb)\n",
    "cm_dt, acc_score_dt = make_confusion_matrix(y_true, y_pred_dt)\n",
    "cm_grad, acc_score_grad = make_confusion_matrix(y_true, y_pred_grad)\n",
    "cm_xgb, acc_score_xgb = make_confusion_matrix(y_true, y_pred_xgb)\n",
    "\n",
    "cms = [cm_nb, cm_dt, cm_grad, cm_xgb]\n",
    "accs = [acc_score_nb, acc_score_dt, acc_score_grad, acc_score_xgb]\n",
    "\n",
    "# naive bayes and svm in my own testing have identical results, so they're together\n",
    "model = [\"NB\", \"Decision Tree\", \"Gradient Boost\", \"XG Boost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"season: {season}\")\n",
    "print(f\"training week: {week}\")\n",
    "print(f\"predicting week: {next_week}\")\n",
    "print('==============')\n",
    "for i in range(0,4):\n",
    "    print('Model: '+ model[i])\n",
    "    print('CM: ')\n",
    "    print(cms[i])\n",
    "    print('Acc: ')\n",
    "    print(round(accs[i]*100, 4))\n",
    "    print('==============')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are pretty interesting. First, it appears that I was right about overfitting. The boosted models and decision tree have the worse accuracies, as far as correct predictions of for class 3 players.\n",
    "\n",
    "Naive Bayes and SVM appear to be very accurate overall, but that seems to be largely due to a larger number of correct 0 predictions.\n",
    "\n",
    "Taking a look at our criteria from the top of this page:\n",
    "\n",
    "1. Correct 3 predictions - NB\n",
    "2. Correct 0 predictions - All of them, with slight lead to SVM\n",
    "3. Bottom right 2x2 has most counts - All equal\n",
    "4. Minimize top row (not including top left) - SVM\n",
    "5. Minimize left column (not including top left) - NB\n",
    "\n",
    "There appears to be a bit of a tie between Naive Bayes and SVM. Since Naive Bayes is the only one that has correct 3 predictions, we'll use that one.\n",
    "\n",
    "[Try again](#test_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Player Pools Based on Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled.rename(columns={'scoring_potential': 'est_scoring_pot', 'DK points': 'avg_points'}, inplace=True)\n",
    "# X_test_scaled['pred_scoring_pot'] = y_pred\n",
    "X_test_scaled['pred_scoring_pot'] = y_pred_nb\n",
    "# X_test_scaled['pred_scoring_pot'] = y_pred_dt\n",
    "# X_test_scaled['pred_scoring_pot'] = y_pred_grad\n",
    "# X_test_scaled['pred_scoring_pot'] = y_pred_xgb\n",
    "X_test_scaled['act_scoring_pot'] = y_true\n",
    "X_test_scaled['act_pts_scored'] = df_check_results['DK points']\n",
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wanting to print entire dataframes from here on\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_one_hot_encode(df, col_idx_start, col_idx_stop, sub_str):\n",
    "    one_hot_columns = (df.iloc[:, col_idx_start:col_idx_stop] == 1).idxmax(1)\n",
    "    df[sub_str] = one_hot_columns\n",
    "    df[sub_str] = df[sub_str].str.replace(sub_str, \"\")\n",
    "    df = df.drop(labels=one_hot_columns, axis=1)\n",
    "    return df\n",
    "\n",
    "X_test = invert_one_hot_encode(X_test_scaled, 8, 13, 'Pos_')\n",
    "X_test.rename(columns={'Pos_': 'Pos'}, inplace=True)\n",
    "X_test = it_ordinal_encode_df(X_test, oe_names, oe_teams, oe_ha, oe_oppts)\n",
    "X_dummy, X_test = unscale_features(sc_salary, sc_points, sc_pts_ald, X_train, X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test.loc[X_test.Pos=='QB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.loc[X_test.Pos=='RB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.loc[X_test.Pos=='WR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.loc[X_test.Pos=='TE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# explanation for this is below\n",
    "def_df = X_test.loc[X_test.Pos=='Def']\n",
    "def_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_for_lineups = X_test\n",
    "df_for_lineups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some observations...\n",
    "\n",
    "The algorithm, so far, is pretty decent at picking everything except for defenses. So that'll need to be re-examined later, but for now, we'll just use all the defenses and see what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build some lineups\n",
    "\n",
    "<a id=\"lineup_builder\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lineup:\n",
    "    \"\"\" \n",
    "    takes the results of the model prediction (dataframe \n",
    "    with attached predictions) and builds out a few lineups \n",
    "    \"\"\"\n",
    "    def __init__(self, df, def_df):\n",
    "        self.df = df\n",
    "        self.def_df = def_df\n",
    "        self.current_salary = 0\n",
    "        self.good_scoring_potential = False\n",
    "        self.no_duplicates = False\n",
    "        self.top_lineups = []\n",
    "        self.qbs = []\n",
    "        self.rbs = []\n",
    "        self.wrs = []\n",
    "        self.tes = []\n",
    "        self.flex = []\n",
    "        self.defs = []\n",
    "    \n",
    "    def find_top_10(self, position):\n",
    "        arr = []\n",
    "        end_of_range = len(self.df.loc[self.df['Pos']==position])\n",
    "        if position == 'Flex':\n",
    "            position_df = self.df.loc[(self.df['Pos']=='RB')|(self.df['Pos']=='TE')|(self.df['Pos']=='WR')]\n",
    "            end_of_range = (len(self.df.loc[self.df['Pos']=='RB'])+\n",
    "                            len(self.df.loc[self.df['Pos']=='WR'])+\n",
    "                            len(self.df.loc[self.df['Pos']=='TE']))\n",
    "        elif position == 'Def':\n",
    "            end_of_range = len(self.def_df)\n",
    "            position_df = self.def_df\n",
    "            position_df = position_df.sort_values(by='avg_points', ascending=False)\n",
    "        else:\n",
    "            position_df = self.df.loc[self.df['Pos']==position]\n",
    "        \n",
    "        # print(position_df)\n",
    "        for row in range(0,end_of_range):\n",
    "            player = {\n",
    "                'name': position_df.iloc[row]['Name'],\n",
    "                'team': position_df.iloc[row]['Team'],\n",
    "                'h/a': position_df.iloc[row]['h/a'],\n",
    "                'pos': position_df.iloc[row]['Pos'],\n",
    "                'salary': position_df.iloc[row]['DK salary'],\n",
    "                'avg_points': position_df.iloc[row]['avg_points'],\n",
    "                'scoring_pot': position_df.iloc[row]['pred_scoring_pot'],\n",
    "                'act_pts':position_df.iloc[row]['act_pts_scored']\n",
    "            }\n",
    "            if len(arr) < end_of_range:\n",
    "                arr.append(player)\n",
    "            else: \n",
    "                break\n",
    "        return arr\n",
    "    \n",
    "    def get_players(self):\n",
    "        top_10_qbs = self.find_top_10(position='QB')\n",
    "        top_10_rbs = self.find_top_10(position='RB')\n",
    "        top_10_wrs = self.find_top_10(position='WR')\n",
    "        top_10_tes = self.find_top_10(position='TE')\n",
    "        top_10_flex = self.find_top_10(position='Flex')\n",
    "        top_10_defs = self.find_top_10(position='Def')\n",
    "        return top_10_qbs, top_10_rbs, top_10_wrs, top_10_tes, top_10_flex, top_10_defs\n",
    "    \n",
    "    def check_salary(self, lineup):\n",
    "        current_salary = 0\n",
    "        for keys in lineup.keys():\n",
    "            current_salary += lineup[keys]['salary']\n",
    "        return current_salary\n",
    "    \n",
    "    def check_duplicates(self, lineup):\n",
    "        rb1_name = lineup['RB1']['name']\n",
    "        rb2_name = lineup['RB2']['name']\n",
    "        flex_name = lineup['Flex']['name']\n",
    "        wr1_name = lineup['WR1']['name']\n",
    "        wr2_name = lineup['WR2']['name']\n",
    "        wr3_name = lineup['WR3']['name']\n",
    "        te_name = lineup['TE']['name']\n",
    "        names = [flex_name, rb1_name, rb2_name, wr1_name, wr2_name, wr3_name, te_name]\n",
    "        while len(names) > 1:\n",
    "            if names[0] in names[1:-1]:\n",
    "                return False\n",
    "            else:\n",
    "                names.pop(0)   \n",
    "        return True\n",
    "    \n",
    "    def check_scoring_potentials(self, lineup):\n",
    "        qb_sp = lineup['QB']['scoring_pot']\n",
    "        rb1_sp = lineup['RB1']['scoring_pot']\n",
    "        rb2_sp = lineup['RB2']['scoring_pot']\n",
    "        flex_sp = lineup['Flex']['scoring_pot']\n",
    "        wr1_sp = lineup['WR1']['scoring_pot']\n",
    "        wr2_sp = lineup['WR2']['scoring_pot']\n",
    "        wr3_sp = lineup['WR3']['scoring_pot']\n",
    "        te_sp = lineup['TE']['scoring_pot']\n",
    "        def_sp = lineup['Def']['scoring_pot']\n",
    "        scor_pots = [qb_sp, flex_sp, rb1_sp, rb2_sp, wr1_sp, wr2_sp, wr3_sp, te_sp, def_sp]\n",
    "        if np.mean(scor_pots) < 1.25:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    \n",
    "    def shuffle_players(self):\n",
    "        lineup = {\n",
    "            'QB': self.qbs[random.randrange(len(self.df.loc[self.df['Pos']=='QB']))],\n",
    "            'RB1': self.rbs[random.randrange(len(self.df.loc[self.df['Pos']=='RB']))],\n",
    "            'RB2': self.rbs[random.randrange(len(self.df.loc[self.df['Pos']=='RB']))],\n",
    "            'WR1': self.wrs[random.randrange(len(self.df.loc[self.df['Pos']=='WR']))],\n",
    "            'WR2': self.wrs[random.randrange(len(self.df.loc[self.df['Pos']=='WR']))],\n",
    "            'WR3': self.wrs[random.randrange(len(self.df.loc[self.df['Pos']=='WR']))],\n",
    "            'TE': self.tes[random.randrange(len(self.df.loc[self.df['Pos']=='TE']))],\n",
    "            'Flex': self.flex[random.randrange(len(self.df.loc[self.df['Pos']=='RB'])+\n",
    "                                               len(self.df.loc[self.df['Pos']=='WR'])+\n",
    "                                               len(self.df.loc[self.df['Pos']=='TE']))],\n",
    "            'Def': self.defs[random.randrange(len(self.def_df))]\n",
    "        }\n",
    "        return lineup\n",
    "    \n",
    "    def build_lineup(self):\n",
    "        self.current_salary = 100*1000\n",
    "        self.no_duplicates = False\n",
    "        self.qbs, self.rbs, self.wrs, self.tes, self.flex, self.defs = self.get_players()\n",
    "        lineup = {\n",
    "            'QB': self.qbs[0],\n",
    "            'RB1': self.rbs[0],\n",
    "            'RB2': self.rbs[1],\n",
    "            'WR1': self.wrs[0],\n",
    "            'WR2': self.wrs[1],\n",
    "            'WR3': self.wrs[2],\n",
    "            'TE': self.tes[0],\n",
    "            'Flex': self.flex[9], # started at the end of flex to avoid duplicating players\n",
    "            'Def': self.defs[0]\n",
    "        }\n",
    "        # in theory, because of the legwork done by the algorithm,\n",
    "        # any lineup should be good as long as it abides by the\n",
    "        # constraints of DraftKings' team structures. So for\n",
    "        # now, this will just give us the first 5 lineups that\n",
    "        # fit within the salary cap and meet the other requirements\n",
    "        \n",
    "        while True:\n",
    "#             print(self.current_salary)\n",
    "#             print(self.no_duplicates)\n",
    "#             print(self.good_scoring_potential)\n",
    "            if (self.current_salary < 50*1000 \n",
    "            and self.current_salary >= 48.5*1000 \n",
    "            and self.no_duplicates\n",
    "            and self.good_scoring_potential):\n",
    "                break\n",
    "            lineup = self.shuffle_players()\n",
    "            # check scoring potential, making sure it averages to at least 1.5\n",
    "            self.good_scoring_potential = self.check_scoring_potentials(lineup)\n",
    "            # check salary, making sure it's between 48.5k and 50k\n",
    "            self.current_salary = self.check_salary(lineup)\n",
    "            # make sure there are no duplicate players\n",
    "            self.no_duplicates = self.check_duplicates(lineup)\n",
    "        \n",
    "        self.top_lineups.append(lineup)\n",
    "        print(f\"added lineup. total lineups: {len(self.top_lineups)}\")\n",
    "    \n",
    "lineup = Lineup(df_for_lineups, def_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this step takes a while\n",
    "for x in range (0,25):\n",
    "    lineup.build_lineup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trash_count = 0\n",
    "for line in lineup.top_lineups:\n",
    "    lineup_df = pd.DataFrame.from_dict(line)\n",
    "    if lineup_df.T['act_pts'].sum() < 120:\n",
    "        trash_count += 1\n",
    "        continue\n",
    "    print(lineup_df.T)\n",
    "    print('======================')\n",
    "    print(\"Salary: \" + str(lineup_df.T['salary'].sum()))\n",
    "    print('======================')\n",
    "    print(\"Pts: \" + str(lineup_df.T['act_pts'].sum()))\n",
    "    print('======================')\n",
    "    print('======================')\n",
    "    print('======================')\n",
    "print(\"trash_count: \" + str(trash_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fda93764f742b83ee64d28c899e316dbaa873d0e3396a11189eda6319c8fd734"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
